{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "#  Import and read the charity_data.csv.\n",
    "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34294</th>\n",
       "      <td>T4</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34295</th>\n",
       "      <td>T4</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34296</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34297</th>\n",
       "      <td>T5</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34298</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1M-5M</td>\n",
       "      <td>N</td>\n",
       "      <td>36500179</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34299 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0                  T10       Independent          C1000    ProductDev   \n",
       "1                   T3       Independent          C2000  Preservation   \n",
       "2                   T5  CompanySponsored          C3000    ProductDev   \n",
       "3                   T3  CompanySponsored          C2000  Preservation   \n",
       "4                   T3       Independent          C1000     Heathcare   \n",
       "...                ...               ...            ...           ...   \n",
       "34294               T4       Independent          C1000    ProductDev   \n",
       "34295               T4  CompanySponsored          C3000    ProductDev   \n",
       "34296               T3  CompanySponsored          C2000  Preservation   \n",
       "34297               T5       Independent          C3000    ProductDev   \n",
       "34298               T3       Independent          C1000  Preservation   \n",
       "\n",
       "       ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS   ASK_AMT  \\\n",
       "0       Association       1              0                      N      5000   \n",
       "1      Co-operative       1         1-9999                      N    108590   \n",
       "2       Association       1              0                      N      5000   \n",
       "3             Trust       1    10000-24999                      N      6692   \n",
       "4             Trust       1  100000-499999                      N    142590   \n",
       "...             ...     ...            ...                    ...       ...   \n",
       "34294   Association       1              0                      N      5000   \n",
       "34295   Association       1              0                      N      5000   \n",
       "34296   Association       1              0                      N      5000   \n",
       "34297   Association       1              0                      N      5000   \n",
       "34298  Co-operative       1          1M-5M                      N  36500179   \n",
       "\n",
       "       IS_SUCCESSFUL  \n",
       "0                  1  \n",
       "1                  1  \n",
       "2                  0  \n",
       "3                  1  \n",
       "4                  1  \n",
       "...              ...  \n",
       "34294              0  \n",
       "34295              0  \n",
       "34296              0  \n",
       "34297              1  \n",
       "34298              0  \n",
       "\n",
       "[34299 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
    "application_df.drop(columns=[\"EIN\", \"NAME\"],inplace=True)\n",
    "application_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE            17\n",
       "AFFILIATION                  6\n",
       "CLASSIFICATION              71\n",
       "USE_CASE                     5\n",
       "ORGANIZATION                 4\n",
       "STATUS                       2\n",
       "INCOME_AMT                   9\n",
       "SPECIAL_CONSIDERATIONS       2\n",
       "ASK_AMT                   8747\n",
       "IS_SUCCESSFUL                2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of unique values in each column.\n",
    "application_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE\n",
       "T3     27037\n",
       "T4      1542\n",
       "T6      1216\n",
       "T5      1173\n",
       "T19     1065\n",
       "T8       737\n",
       "T7       725\n",
       "T10      528\n",
       "T9       156\n",
       "T13       66\n",
       "T12       27\n",
       "T2        16\n",
       "T25        3\n",
       "T14        3\n",
       "T29        2\n",
       "T15        2\n",
       "T17        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at APPLICATION_TYPE value counts to identify and replace with \"Other\"\n",
    "app_count = application_df[\"APPLICATION_TYPE\"].value_counts()\n",
    "app_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE\n",
       "T3       27037\n",
       "T4        1542\n",
       "T6        1216\n",
       "T5        1173\n",
       "T19       1065\n",
       "T8         737\n",
       "T7         725\n",
       "T10        528\n",
       "Other      276\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of application types to be replaced\n",
    "# use the variable name `application_types_to_replace`\n",
    "application_types_to_replace = app_count.index[8:]\n",
    "\n",
    "# Replace in dataframe\n",
    "for app in application_types_to_replace:\n",
    "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
    "\n",
    "# Check to make sure replacement was successful\n",
    "application_df['APPLICATION_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLASSIFICATION\n",
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "         ...  \n",
       "C4120        1\n",
       "C8210        1\n",
       "C2561        1\n",
       "C4500        1\n",
       "C2150        1\n",
       "Name: count, Length: 71, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at CLASSIFICATION value counts to identify and replace with \"Other\"\n",
    "class_count = application_df[\"CLASSIFICATION\"].value_counts()\n",
    "class_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLASSIFICATION\n",
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "C7000      777\n",
       "C1700      287\n",
       "C4000      194\n",
       "C5000      116\n",
       "C1270      114\n",
       "C2700      104\n",
       "C2800       95\n",
       "C7100       75\n",
       "C1300       58\n",
       "C1280       50\n",
       "C1230       36\n",
       "C1400       34\n",
       "C7200       32\n",
       "C2300       32\n",
       "C1240       30\n",
       "C8000       20\n",
       "C7120       18\n",
       "C1500       16\n",
       "C1800       15\n",
       "C6000       15\n",
       "C1250       14\n",
       "C8200       11\n",
       "C1238       10\n",
       "C1278       10\n",
       "C1235        9\n",
       "C1237        9\n",
       "C7210        7\n",
       "C2400        6\n",
       "C1720        6\n",
       "C4100        6\n",
       "C1257        5\n",
       "C1600        5\n",
       "C1260        3\n",
       "C2710        3\n",
       "C0           3\n",
       "C3200        2\n",
       "C1234        2\n",
       "C1246        2\n",
       "C1267        2\n",
       "C1256        2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You may find it helpful to look at CLASSIFICATION value counts > 1\n",
    "class_count[class_count > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLASSIFICATION\n",
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "C7000      777\n",
       "C1700      287\n",
       "C4000      194\n",
       "C5000      116\n",
       "C1270      114\n",
       "C2700      104\n",
       "C2800       95\n",
       "C7100       75\n",
       "C1300       58\n",
       "C1280       50\n",
       "C1230       36\n",
       "C1400       34\n",
       "C7200       32\n",
       "C2300       32\n",
       "C1240       30\n",
       "Other       26\n",
       "C8000       20\n",
       "C7120       18\n",
       "C1500       16\n",
       "C6000       15\n",
       "C1800       15\n",
       "C1250       14\n",
       "C8200       11\n",
       "C1238       10\n",
       "C1278       10\n",
       "C1237        9\n",
       "C1235        9\n",
       "C7210        7\n",
       "C1720        6\n",
       "C2400        6\n",
       "C4100        6\n",
       "C1257        5\n",
       "C1600        5\n",
       "C1260        3\n",
       "C2710        3\n",
       "C0           3\n",
       "C1267        2\n",
       "C1256        2\n",
       "C1234        2\n",
       "C1246        2\n",
       "C3200        2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of classifications to be replaced\n",
    "# use the variable name `classifications_to_replace`\n",
    "classifications_to_replace = class_count[class_count < 2].index\n",
    "\n",
    "# Replace in dataframe\n",
    "for cls in classifications_to_replace:\n",
    "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
    "\n",
    "# Check to make sure replacement was successful\n",
    "application_df['CLASSIFICATION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34299 entries, 0 to 34298\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   APPLICATION_TYPE        34299 non-null  object\n",
      " 1   AFFILIATION             34299 non-null  object\n",
      " 2   CLASSIFICATION          34299 non-null  object\n",
      " 3   USE_CASE                34299 non-null  object\n",
      " 4   ORGANIZATION            34299 non-null  object\n",
      " 5   STATUS                  34299 non-null  int64 \n",
      " 6   INCOME_AMT              34299 non-null  object\n",
      " 7   SPECIAL_CONSIDERATIONS  34299 non-null  object\n",
      " 8   ASK_AMT                 34299 non-null  int64 \n",
      " 9   IS_SUCCESSFUL           34299 non-null  int64 \n",
      "dtypes: int64(3), object(7)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "application_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34294</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34295</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34296</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34297</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34298</th>\n",
       "      <td>1</td>\n",
       "      <td>36500179</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34299 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       STATUS   ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
       "0           1      5000              1                   False   \n",
       "1           1    108590              1                   False   \n",
       "2           1      5000              0                   False   \n",
       "3           1      6692              1                   False   \n",
       "4           1    142590              1                   False   \n",
       "...       ...       ...            ...                     ...   \n",
       "34294       1      5000              0                   False   \n",
       "34295       1      5000              0                   False   \n",
       "34296       1      5000              0                   False   \n",
       "34297       1      5000              1                   False   \n",
       "34298       1  36500179              0                   False   \n",
       "\n",
       "       APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  \\\n",
       "0                      True                 False                False   \n",
       "1                     False                 False                 True   \n",
       "2                     False                 False                False   \n",
       "3                     False                 False                 True   \n",
       "4                     False                 False                 True   \n",
       "...                     ...                   ...                  ...   \n",
       "34294                 False                 False                False   \n",
       "34295                 False                 False                False   \n",
       "34296                 False                 False                 True   \n",
       "34297                 False                 False                False   \n",
       "34298                 False                 False                 True   \n",
       "\n",
       "       APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  ...  \\\n",
       "0                    False                False                False  ...   \n",
       "1                    False                False                False  ...   \n",
       "2                    False                 True                False  ...   \n",
       "3                    False                False                False  ...   \n",
       "4                    False                False                False  ...   \n",
       "...                    ...                  ...                  ...  ...   \n",
       "34294                 True                False                False  ...   \n",
       "34295                 True                False                False  ...   \n",
       "34296                False                False                False  ...   \n",
       "34297                False                 True                False  ...   \n",
       "34298                False                False                False  ...   \n",
       "\n",
       "       INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0                  False                   False                     False   \n",
       "1                   True                   False                     False   \n",
       "2                  False                   False                     False   \n",
       "3                  False                    True                     False   \n",
       "4                  False                   False                      True   \n",
       "...                  ...                     ...                       ...   \n",
       "34294              False                   False                     False   \n",
       "34295              False                   False                     False   \n",
       "34296              False                   False                     False   \n",
       "34297              False                   False                     False   \n",
       "34298              False                   False                     False   \n",
       "\n",
       "       INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                   False             False                   False   \n",
       "1                   False             False                   False   \n",
       "2                   False             False                   False   \n",
       "3                   False             False                   False   \n",
       "4                   False             False                   False   \n",
       "...                   ...               ...                     ...   \n",
       "34294               False             False                   False   \n",
       "34295               False             False                   False   \n",
       "34296               False             False                   False   \n",
       "34297               False             False                   False   \n",
       "34298               False              True                   False   \n",
       "\n",
       "       INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0                False              False                      True   \n",
       "1                False              False                      True   \n",
       "2                False              False                      True   \n",
       "3                False              False                      True   \n",
       "4                False              False                      True   \n",
       "...                ...                ...                       ...   \n",
       "34294            False              False                      True   \n",
       "34295            False              False                      True   \n",
       "34296            False              False                      True   \n",
       "34297            False              False                      True   \n",
       "34298            False              False                      True   \n",
       "\n",
       "       SPECIAL_CONSIDERATIONS_Y  \n",
       "0                         False  \n",
       "1                         False  \n",
       "2                         False  \n",
       "3                         False  \n",
       "4                         False  \n",
       "...                         ...  \n",
       "34294                     False  \n",
       "34295                     False  \n",
       "34296                     False  \n",
       "34297                     False  \n",
       "34298                     False  \n",
       "\n",
       "[34299 rows x 84 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical data to numeric with `pd.get_dummies`\n",
    "application_dummies_df = pd.get_dummies(application_df[[\"APPLICATION_TYPE\",\"AFFILIATION\",\"CLASSIFICATION\",\"USE_CASE\",\"ORGANIZATION\",\"INCOME_AMT\",\"SPECIAL_CONSIDERATIONS\"]])\n",
    "application_df.drop(columns=[\"APPLICATION_TYPE\",\"AFFILIATION\",\"CLASSIFICATION\",\"USE_CASE\",\"ORGANIZATION\",\"INCOME_AMT\",\"SPECIAL_CONSIDERATIONS\"],inplace=True)\n",
    "application_dummies_df = pd.merge(application_df, application_dummies_df, how=\"inner\",left_index=True,right_index=True)\n",
    "application_dummies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = application_dummies_df['IS_SUCCESSFUL']\n",
    "\n",
    "# Separate the X variable, the features\n",
    "X = application_dummies_df.drop(columns=['IS_SUCCESSFUL']).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,random_state=1,train_size=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile, Train and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,720</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,430</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_31 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │         \u001b[38;5;34m6,720\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_32 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │         \u001b[38;5;34m2,430\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_33 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m31\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,181</span> (35.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,181\u001b[0m (35.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,181</span> (35.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,181\u001b[0m (35.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "input_features = len(X_train[0])\n",
    "layer1 =  80\n",
    "layer2 = 30\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=layer1, activation=\"relu\", input_dim=input_features))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 0.7056 - loss: 0.5955\n",
      "Epoch 2/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 816us/step - accuracy: 0.7283 - loss: 0.5551\n",
      "Epoch 3/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 758us/step - accuracy: 0.7319 - loss: 0.5501\n",
      "Epoch 4/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 737us/step - accuracy: 0.7341 - loss: 0.5457\n",
      "Epoch 5/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 705us/step - accuracy: 0.7280 - loss: 0.5484\n",
      "Epoch 6/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 725us/step - accuracy: 0.7335 - loss: 0.5451\n",
      "Epoch 7/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 718us/step - accuracy: 0.7401 - loss: 0.5378\n",
      "Epoch 8/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 800us/step - accuracy: 0.7343 - loss: 0.5421\n",
      "Epoch 9/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 756us/step - accuracy: 0.7334 - loss: 0.5427\n",
      "Epoch 10/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 719us/step - accuracy: 0.7384 - loss: 0.5387\n",
      "Epoch 11/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 790us/step - accuracy: 0.7398 - loss: 0.5378\n",
      "Epoch 12/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 750us/step - accuracy: 0.7316 - loss: 0.5439\n",
      "Epoch 13/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 777us/step - accuracy: 0.7317 - loss: 0.5430\n",
      "Epoch 14/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 774us/step - accuracy: 0.7397 - loss: 0.5351\n",
      "Epoch 15/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 735us/step - accuracy: 0.7387 - loss: 0.5360\n",
      "Epoch 16/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 733us/step - accuracy: 0.7390 - loss: 0.5377\n",
      "Epoch 17/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - accuracy: 0.7400 - loss: 0.5347\n",
      "Epoch 18/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 745us/step - accuracy: 0.7433 - loss: 0.5314\n",
      "Epoch 19/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 702us/step - accuracy: 0.7364 - loss: 0.5373\n",
      "Epoch 20/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 722us/step - accuracy: 0.7397 - loss: 0.5369\n",
      "Epoch 21/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 824us/step - accuracy: 0.7385 - loss: 0.5359\n",
      "Epoch 22/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 886us/step - accuracy: 0.7408 - loss: 0.5334\n",
      "Epoch 23/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 826us/step - accuracy: 0.7354 - loss: 0.5382\n",
      "Epoch 24/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 804us/step - accuracy: 0.7420 - loss: 0.5342\n",
      "Epoch 25/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 846us/step - accuracy: 0.7396 - loss: 0.5354\n",
      "Epoch 26/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 808us/step - accuracy: 0.7427 - loss: 0.5330\n",
      "Epoch 27/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 813us/step - accuracy: 0.7404 - loss: 0.5346\n",
      "Epoch 28/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 819us/step - accuracy: 0.7398 - loss: 0.5343\n",
      "Epoch 29/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 830us/step - accuracy: 0.7384 - loss: 0.5354\n",
      "Epoch 30/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 813us/step - accuracy: 0.7381 - loss: 0.5326\n",
      "Epoch 31/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 817us/step - accuracy: 0.7381 - loss: 0.5361\n",
      "Epoch 32/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 856us/step - accuracy: 0.7386 - loss: 0.5382\n",
      "Epoch 33/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 815us/step - accuracy: 0.7412 - loss: 0.5361\n",
      "Epoch 34/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 817us/step - accuracy: 0.7391 - loss: 0.5366\n",
      "Epoch 35/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 831us/step - accuracy: 0.7378 - loss: 0.5377\n",
      "Epoch 36/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 818us/step - accuracy: 0.7384 - loss: 0.5359\n",
      "Epoch 37/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 820us/step - accuracy: 0.7394 - loss: 0.5357\n",
      "Epoch 38/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 849us/step - accuracy: 0.7371 - loss: 0.5332\n",
      "Epoch 39/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 846us/step - accuracy: 0.7439 - loss: 0.5313\n",
      "Epoch 40/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 812us/step - accuracy: 0.7411 - loss: 0.5321\n",
      "Epoch 41/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 823us/step - accuracy: 0.7401 - loss: 0.5369\n",
      "Epoch 42/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 849us/step - accuracy: 0.7379 - loss: 0.5348\n",
      "Epoch 43/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 816us/step - accuracy: 0.7413 - loss: 0.5319\n",
      "Epoch 44/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 808us/step - accuracy: 0.7395 - loss: 0.5339\n",
      "Epoch 45/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 834us/step - accuracy: 0.7385 - loss: 0.5361\n",
      "Epoch 46/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 829us/step - accuracy: 0.7399 - loss: 0.5330\n",
      "Epoch 47/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 818us/step - accuracy: 0.7440 - loss: 0.5292\n",
      "Epoch 48/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 844us/step - accuracy: 0.7418 - loss: 0.5305\n",
      "Epoch 49/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 822us/step - accuracy: 0.7407 - loss: 0.5321\n",
      "Epoch 50/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 835us/step - accuracy: 0.7463 - loss: 0.5268\n",
      "Epoch 51/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841us/step - accuracy: 0.7440 - loss: 0.5301\n",
      "Epoch 52/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825us/step - accuracy: 0.7410 - loss: 0.5319\n",
      "Epoch 53/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 821us/step - accuracy: 0.7390 - loss: 0.5340\n",
      "Epoch 54/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825us/step - accuracy: 0.7421 - loss: 0.5274\n",
      "Epoch 55/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 832us/step - accuracy: 0.7445 - loss: 0.5276\n",
      "Epoch 56/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - accuracy: 0.7411 - loss: 0.5311\n",
      "Epoch 57/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 955us/step - accuracy: 0.7400 - loss: 0.5312\n",
      "Epoch 58/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 866us/step - accuracy: 0.7442 - loss: 0.5269\n",
      "Epoch 59/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 885us/step - accuracy: 0.7443 - loss: 0.5305\n",
      "Epoch 60/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 932us/step - accuracy: 0.7400 - loss: 0.5338\n",
      "Epoch 61/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 869us/step - accuracy: 0.7439 - loss: 0.5288\n",
      "Epoch 62/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 936us/step - accuracy: 0.7439 - loss: 0.5300\n",
      "Epoch 63/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 918us/step - accuracy: 0.7431 - loss: 0.5298\n",
      "Epoch 64/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 856us/step - accuracy: 0.7438 - loss: 0.5279\n",
      "Epoch 65/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 963us/step - accuracy: 0.7386 - loss: 0.5330\n",
      "Epoch 66/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 918us/step - accuracy: 0.7388 - loss: 0.5354\n",
      "Epoch 67/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - accuracy: 0.7405 - loss: 0.5334\n",
      "Epoch 68/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 813us/step - accuracy: 0.7428 - loss: 0.5324\n",
      "Epoch 69/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 903us/step - accuracy: 0.7408 - loss: 0.5289\n",
      "Epoch 70/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 824us/step - accuracy: 0.7420 - loss: 0.5296\n",
      "Epoch 71/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 814us/step - accuracy: 0.7428 - loss: 0.5275\n",
      "Epoch 72/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 929us/step - accuracy: 0.7433 - loss: 0.5302\n",
      "Epoch 73/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 889us/step - accuracy: 0.7427 - loss: 0.5274\n",
      "Epoch 74/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 908us/step - accuracy: 0.7380 - loss: 0.5350\n",
      "Epoch 75/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 859us/step - accuracy: 0.7455 - loss: 0.5283\n",
      "Epoch 76/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 900us/step - accuracy: 0.7430 - loss: 0.5293\n",
      "Epoch 77/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 953us/step - accuracy: 0.7387 - loss: 0.5343\n",
      "Epoch 78/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 884us/step - accuracy: 0.7384 - loss: 0.5329\n",
      "Epoch 79/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 926us/step - accuracy: 0.7426 - loss: 0.5289\n",
      "Epoch 80/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 892us/step - accuracy: 0.7398 - loss: 0.5270\n",
      "Epoch 81/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 893us/step - accuracy: 0.7386 - loss: 0.5331\n",
      "Epoch 82/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 816us/step - accuracy: 0.7418 - loss: 0.5296\n",
      "Epoch 83/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825us/step - accuracy: 0.7434 - loss: 0.5287\n",
      "Epoch 84/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 818us/step - accuracy: 0.7480 - loss: 0.5233\n",
      "Epoch 85/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 817us/step - accuracy: 0.7390 - loss: 0.5331\n",
      "Epoch 86/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841us/step - accuracy: 0.7442 - loss: 0.5301\n",
      "Epoch 87/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 821us/step - accuracy: 0.7455 - loss: 0.5244\n",
      "Epoch 88/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838us/step - accuracy: 0.7442 - loss: 0.5231\n",
      "Epoch 89/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 823us/step - accuracy: 0.7409 - loss: 0.5294\n",
      "Epoch 90/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 810us/step - accuracy: 0.7428 - loss: 0.5289\n",
      "Epoch 91/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838us/step - accuracy: 0.7393 - loss: 0.5315\n",
      "Epoch 92/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 808us/step - accuracy: 0.7373 - loss: 0.5333\n",
      "Epoch 93/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 818us/step - accuracy: 0.7433 - loss: 0.5272\n",
      "Epoch 94/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 836us/step - accuracy: 0.7422 - loss: 0.5277\n",
      "Epoch 95/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 821us/step - accuracy: 0.7428 - loss: 0.5288\n",
      "Epoch 96/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 805us/step - accuracy: 0.7413 - loss: 0.5326\n",
      "Epoch 97/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 849us/step - accuracy: 0.7432 - loss: 0.5247\n",
      "Epoch 98/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 816us/step - accuracy: 0.7425 - loss: 0.5298\n",
      "Epoch 99/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 935us/step - accuracy: 0.7397 - loss: 0.5293\n",
      "Epoch 100/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - accuracy: 0.7489 - loss: 0.5230\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 - 0s - 1ms/step - accuracy: 0.7258 - loss: 0.5617\n",
      "Loss: 0.5616835355758667, Accuracy: 0.7257531881332397\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=h5\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Export our model to HDF5 file\n",
    "nn.save(\"AlphabetSoupCharity.h5\", save_format='h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Increase Number of Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rmt20\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_134\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_134\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_578 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,720</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_579 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,430</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_580 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">310</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_581 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_578 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │         \u001b[38;5;34m6,720\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_579 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │         \u001b[38;5;34m2,430\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_580 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m310\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_581 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m11\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,471</span> (37.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,471\u001b[0m (37.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,471</span> (37.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,471\u001b[0m (37.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "input_features = len(X_train[0])\n",
    "layer1 =  80\n",
    "layer2 = 30\n",
    "layer3 = 10\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=layer1, activation=\"relu\", input_dim=input_features))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=layer2, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=layer3, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1076,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 885us/step - accuracy: 0.7030 - loss: 0.5890\n",
      "Epoch 2/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7325 - loss: 0.5494\n",
      "Epoch 3/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 777us/step - accuracy: 0.7260 - loss: 0.5510\n",
      "Epoch 4/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 767us/step - accuracy: 0.7333 - loss: 0.5449\n",
      "Epoch 5/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 918us/step - accuracy: 0.7394 - loss: 0.5404\n",
      "Epoch 6/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 780us/step - accuracy: 0.7320 - loss: 0.5433\n",
      "Epoch 7/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 769us/step - accuracy: 0.7353 - loss: 0.5443\n",
      "Epoch 8/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 888us/step - accuracy: 0.7341 - loss: 0.5438\n",
      "Epoch 9/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 764us/step - accuracy: 0.7414 - loss: 0.5346\n",
      "Epoch 10/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 775us/step - accuracy: 0.7408 - loss: 0.5365\n",
      "Epoch 11/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 901us/step - accuracy: 0.7413 - loss: 0.5374\n",
      "Epoch 12/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 766us/step - accuracy: 0.7362 - loss: 0.5383\n",
      "Epoch 13/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 771us/step - accuracy: 0.7362 - loss: 0.5399\n",
      "Epoch 14/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 909us/step - accuracy: 0.7359 - loss: 0.5390\n",
      "Epoch 15/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 754us/step - accuracy: 0.7367 - loss: 0.5404\n",
      "Epoch 16/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 736us/step - accuracy: 0.7381 - loss: 0.5371\n",
      "Epoch 17/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 854us/step - accuracy: 0.7333 - loss: 0.5404\n",
      "Epoch 18/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 740us/step - accuracy: 0.7356 - loss: 0.5400\n",
      "Epoch 19/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 729us/step - accuracy: 0.7378 - loss: 0.5406\n",
      "Epoch 20/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851us/step - accuracy: 0.7408 - loss: 0.5317\n",
      "Epoch 21/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 749us/step - accuracy: 0.7338 - loss: 0.5400\n",
      "Epoch 22/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 738us/step - accuracy: 0.7382 - loss: 0.5375\n",
      "Epoch 23/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 0.7365 - loss: 0.5370\n",
      "Epoch 24/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 757us/step - accuracy: 0.7362 - loss: 0.5386\n",
      "Epoch 25/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 730us/step - accuracy: 0.7371 - loss: 0.5370\n",
      "Epoch 26/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 848us/step - accuracy: 0.7352 - loss: 0.5397\n",
      "Epoch 27/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 734us/step - accuracy: 0.7359 - loss: 0.5384\n",
      "Epoch 28/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 747us/step - accuracy: 0.7429 - loss: 0.5291\n",
      "Epoch 29/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 865us/step - accuracy: 0.7406 - loss: 0.5349\n",
      "Epoch 30/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 767us/step - accuracy: 0.7362 - loss: 0.5387\n",
      "Epoch 31/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 747us/step - accuracy: 0.7367 - loss: 0.5393\n",
      "Epoch 32/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 879us/step - accuracy: 0.7387 - loss: 0.5365\n",
      "Epoch 33/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 743us/step - accuracy: 0.7378 - loss: 0.5347\n",
      "Epoch 34/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 745us/step - accuracy: 0.7311 - loss: 0.5422\n",
      "Epoch 35/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 0.7397 - loss: 0.5337\n",
      "Epoch 36/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 732us/step - accuracy: 0.7444 - loss: 0.5286\n",
      "Epoch 37/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 827us/step - accuracy: 0.7369 - loss: 0.5361\n",
      "Epoch 38/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 777us/step - accuracy: 0.7354 - loss: 0.5364\n",
      "Epoch 39/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 734us/step - accuracy: 0.7420 - loss: 0.5336\n",
      "Epoch 40/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838us/step - accuracy: 0.7371 - loss: 0.5362\n",
      "Epoch 41/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 757us/step - accuracy: 0.7385 - loss: 0.5330\n",
      "Epoch 42/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 764us/step - accuracy: 0.7383 - loss: 0.5356\n",
      "Epoch 43/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841us/step - accuracy: 0.7388 - loss: 0.5343\n",
      "Epoch 44/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 770us/step - accuracy: 0.7386 - loss: 0.5340\n",
      "Epoch 45/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 727us/step - accuracy: 0.7379 - loss: 0.5316\n",
      "Epoch 46/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 863us/step - accuracy: 0.7397 - loss: 0.5352\n",
      "Epoch 47/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 734us/step - accuracy: 0.7417 - loss: 0.5314\n",
      "Epoch 48/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 731us/step - accuracy: 0.7416 - loss: 0.5307\n",
      "Epoch 49/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 867us/step - accuracy: 0.7372 - loss: 0.5365\n",
      "Epoch 50/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 741us/step - accuracy: 0.7385 - loss: 0.5307\n",
      "Epoch 51/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 733us/step - accuracy: 0.7395 - loss: 0.5362\n",
      "Epoch 52/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 855us/step - accuracy: 0.7419 - loss: 0.5292\n",
      "Epoch 53/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 737us/step - accuracy: 0.7358 - loss: 0.5347\n",
      "Epoch 54/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 743us/step - accuracy: 0.7417 - loss: 0.5325\n",
      "Epoch 55/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 801us/step - accuracy: 0.7407 - loss: 0.5308\n",
      "Epoch 56/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 729us/step - accuracy: 0.7402 - loss: 0.5310\n",
      "Epoch 57/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 740us/step - accuracy: 0.7402 - loss: 0.5337\n",
      "Epoch 58/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 854us/step - accuracy: 0.7426 - loss: 0.5300\n",
      "Epoch 59/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 733us/step - accuracy: 0.7402 - loss: 0.5305\n",
      "Epoch 60/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 740us/step - accuracy: 0.7388 - loss: 0.5328\n",
      "Epoch 61/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 799us/step - accuracy: 0.7403 - loss: 0.5284\n",
      "Epoch 62/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 742us/step - accuracy: 0.7391 - loss: 0.5315\n",
      "Epoch 63/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 738us/step - accuracy: 0.7428 - loss: 0.5314\n",
      "Epoch 64/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 869us/step - accuracy: 0.7418 - loss: 0.5293\n",
      "Epoch 65/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 735us/step - accuracy: 0.7402 - loss: 0.5305\n",
      "Epoch 66/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 739us/step - accuracy: 0.7389 - loss: 0.5326\n",
      "Epoch 67/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838us/step - accuracy: 0.7389 - loss: 0.5339\n",
      "Epoch 68/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 752us/step - accuracy: 0.7404 - loss: 0.5337\n",
      "Epoch 69/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 758us/step - accuracy: 0.7427 - loss: 0.5307\n",
      "Epoch 70/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 776us/step - accuracy: 0.7433 - loss: 0.5275\n",
      "Epoch 71/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 744us/step - accuracy: 0.7368 - loss: 0.5356\n",
      "Epoch 72/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 797us/step - accuracy: 0.7391 - loss: 0.5331\n",
      "Epoch 73/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 752us/step - accuracy: 0.7420 - loss: 0.5307\n",
      "Epoch 74/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 735us/step - accuracy: 0.7429 - loss: 0.5271\n",
      "Epoch 75/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 0.7451 - loss: 0.5253\n",
      "Epoch 76/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 740us/step - accuracy: 0.7454 - loss: 0.5251\n",
      "Epoch 77/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 733us/step - accuracy: 0.7439 - loss: 0.5294\n",
      "Epoch 78/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 865us/step - accuracy: 0.7436 - loss: 0.5277\n",
      "Epoch 79/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 755us/step - accuracy: 0.7467 - loss: 0.5266\n",
      "Epoch 80/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 743us/step - accuracy: 0.7432 - loss: 0.5283\n",
      "Epoch 81/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 866us/step - accuracy: 0.7432 - loss: 0.5306\n",
      "Epoch 82/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 758us/step - accuracy: 0.7396 - loss: 0.5316\n",
      "Epoch 83/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 817us/step - accuracy: 0.7407 - loss: 0.5315\n",
      "Epoch 84/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 759us/step - accuracy: 0.7405 - loss: 0.5320\n",
      "Epoch 85/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 742us/step - accuracy: 0.7433 - loss: 0.5289\n",
      "Epoch 86/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 873us/step - accuracy: 0.7405 - loss: 0.5287\n",
      "Epoch 87/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 750us/step - accuracy: 0.7418 - loss: 0.5285\n",
      "Epoch 88/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 741us/step - accuracy: 0.7400 - loss: 0.5280\n",
      "Epoch 89/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 857us/step - accuracy: 0.7450 - loss: 0.5229\n",
      "Epoch 90/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 753us/step - accuracy: 0.7381 - loss: 0.5343\n",
      "Epoch 91/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 740us/step - accuracy: 0.7446 - loss: 0.5262\n",
      "Epoch 92/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 861us/step - accuracy: 0.7431 - loss: 0.5267\n",
      "Epoch 93/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 749us/step - accuracy: 0.7456 - loss: 0.5261\n",
      "Epoch 94/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851us/step - accuracy: 0.7439 - loss: 0.5273\n",
      "Epoch 95/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 750us/step - accuracy: 0.7447 - loss: 0.5286\n",
      "Epoch 96/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 747us/step - accuracy: 0.7447 - loss: 0.5244\n",
      "Epoch 97/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 863us/step - accuracy: 0.7462 - loss: 0.5205\n",
      "Epoch 98/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 748us/step - accuracy: 0.7427 - loss: 0.5289\n",
      "Epoch 99/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 748us/step - accuracy: 0.7390 - loss: 0.5313\n",
      "Epoch 100/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 828us/step - accuracy: 0.7410 - loss: 0.5286\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - 2ms/step - accuracy: 0.7287 - loss: 0.5594\n",
      "Loss: 0.5594280362129211, Accuracy: 0.7287463545799255\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increase Layers(n=80,30,10,1): 0.7287463545799255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Increase Number of Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rmt20\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_139\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_139\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_594 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_595 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,840</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_596 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_594 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)            │        \u001b[38;5;34m10,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_595 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │         \u001b[38;5;34m4,840\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_596 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m41\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,961</span> (58.44 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,961\u001b[0m (58.44 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,961</span> (58.44 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m14,961\u001b[0m (58.44 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "input_features = len(X_train[0])\n",
    "layer1 =  120\n",
    "layer2 = 40\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=layer1, activation=\"relu\", input_dim=input_features))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 934us/step - accuracy: 0.7185 - loss: 0.5764\n",
      "Epoch 2/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 883us/step - accuracy: 0.7355 - loss: 0.5482\n",
      "Epoch 3/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 743us/step - accuracy: 0.7320 - loss: 0.5492\n",
      "Epoch 4/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 971us/step - accuracy: 0.7296 - loss: 0.5467\n",
      "Epoch 5/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 773us/step - accuracy: 0.7326 - loss: 0.5446\n",
      "Epoch 6/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 771us/step - accuracy: 0.7294 - loss: 0.5472\n",
      "Epoch 7/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 899us/step - accuracy: 0.7318 - loss: 0.5477\n",
      "Epoch 8/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851us/step - accuracy: 0.7346 - loss: 0.5414\n",
      "Epoch 9/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 878us/step - accuracy: 0.7381 - loss: 0.5393\n",
      "Epoch 10/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 764us/step - accuracy: 0.7423 - loss: 0.5337\n",
      "Epoch 11/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 755us/step - accuracy: 0.7349 - loss: 0.5392\n",
      "Epoch 12/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 866us/step - accuracy: 0.7364 - loss: 0.5378\n",
      "Epoch 13/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 809us/step - accuracy: 0.7363 - loss: 0.5440\n",
      "Epoch 14/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 768us/step - accuracy: 0.7346 - loss: 0.5380\n",
      "Epoch 15/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 898us/step - accuracy: 0.7352 - loss: 0.5391\n",
      "Epoch 16/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 736us/step - accuracy: 0.7384 - loss: 0.5369\n",
      "Epoch 17/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 759us/step - accuracy: 0.7411 - loss: 0.5346\n",
      "Epoch 18/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 869us/step - accuracy: 0.7354 - loss: 0.5409\n",
      "Epoch 19/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 743us/step - accuracy: 0.7391 - loss: 0.5374\n",
      "Epoch 20/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 752us/step - accuracy: 0.7382 - loss: 0.5372\n",
      "Epoch 21/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 0.7358 - loss: 0.5388\n",
      "Epoch 22/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 707us/step - accuracy: 0.7341 - loss: 0.5408\n",
      "Epoch 23/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 703us/step - accuracy: 0.7394 - loss: 0.5351\n",
      "Epoch 24/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 973us/step - accuracy: 0.7403 - loss: 0.5350\n",
      "Epoch 25/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 761us/step - accuracy: 0.7443 - loss: 0.5316\n",
      "Epoch 26/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 719us/step - accuracy: 0.7399 - loss: 0.5356\n",
      "Epoch 27/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 941us/step - accuracy: 0.7345 - loss: 0.5384\n",
      "Epoch 28/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - accuracy: 0.7435 - loss: 0.5308\n",
      "Epoch 29/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 744us/step - accuracy: 0.7390 - loss: 0.5366\n",
      "Epoch 30/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 0.7411 - loss: 0.5330\n",
      "Epoch 31/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 0.7395 - loss: 0.5339\n",
      "Epoch 32/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 800us/step - accuracy: 0.7413 - loss: 0.5354\n",
      "Epoch 33/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 764us/step - accuracy: 0.7447 - loss: 0.5308\n",
      "Epoch 34/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 750us/step - accuracy: 0.7408 - loss: 0.5319\n",
      "Epoch 35/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - accuracy: 0.7425 - loss: 0.5313\n",
      "Epoch 36/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 762us/step - accuracy: 0.7407 - loss: 0.5306\n",
      "Epoch 37/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 708us/step - accuracy: 0.7392 - loss: 0.5340\n",
      "Epoch 38/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 733us/step - accuracy: 0.7426 - loss: 0.5294\n",
      "Epoch 39/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - accuracy: 0.7442 - loss: 0.5305\n",
      "Epoch 40/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - accuracy: 0.7403 - loss: 0.5360\n",
      "Epoch 41/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 747us/step - accuracy: 0.7412 - loss: 0.5357\n",
      "Epoch 42/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 845us/step - accuracy: 0.7410 - loss: 0.5326\n",
      "Epoch 43/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - accuracy: 0.7385 - loss: 0.5358\n",
      "Epoch 44/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 722us/step - accuracy: 0.7400 - loss: 0.5314\n",
      "Epoch 45/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 867us/step - accuracy: 0.7445 - loss: 0.5294\n",
      "Epoch 46/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - accuracy: 0.7477 - loss: 0.5286\n",
      "Epoch 47/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 718us/step - accuracy: 0.7434 - loss: 0.5295\n",
      "Epoch 48/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 854us/step - accuracy: 0.7387 - loss: 0.5346\n",
      "Epoch 49/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - accuracy: 0.7398 - loss: 0.5295\n",
      "Epoch 50/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721us/step - accuracy: 0.7376 - loss: 0.5332\n",
      "Epoch 51/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - accuracy: 0.7396 - loss: 0.5320\n",
      "Epoch 52/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 730us/step - accuracy: 0.7447 - loss: 0.5277\n",
      "Epoch 53/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 714us/step - accuracy: 0.7392 - loss: 0.5347\n",
      "Epoch 54/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 839us/step - accuracy: 0.7402 - loss: 0.5316\n",
      "Epoch 55/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - accuracy: 0.7406 - loss: 0.5324\n",
      "Epoch 56/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 725us/step - accuracy: 0.7399 - loss: 0.5331\n",
      "Epoch 57/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 769us/step - accuracy: 0.7416 - loss: 0.5302\n",
      "Epoch 58/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - accuracy: 0.7428 - loss: 0.5296\n",
      "Epoch 59/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - accuracy: 0.7421 - loss: 0.5286\n",
      "Epoch 60/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 855us/step - accuracy: 0.7375 - loss: 0.5366\n",
      "Epoch 61/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 707us/step - accuracy: 0.7391 - loss: 0.5331\n",
      "Epoch 62/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - accuracy: 0.7440 - loss: 0.5294\n",
      "Epoch 63/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 842us/step - accuracy: 0.7440 - loss: 0.5290\n",
      "Epoch 64/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - accuracy: 0.7405 - loss: 0.5303\n",
      "Epoch 65/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 707us/step - accuracy: 0.7407 - loss: 0.5301\n",
      "Epoch 66/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 852us/step - accuracy: 0.7441 - loss: 0.5297\n",
      "Epoch 67/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - accuracy: 0.7356 - loss: 0.5370\n",
      "Epoch 68/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713us/step - accuracy: 0.7400 - loss: 0.5320\n",
      "Epoch 69/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 842us/step - accuracy: 0.7412 - loss: 0.5317\n",
      "Epoch 70/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 714us/step - accuracy: 0.7451 - loss: 0.5240\n",
      "Epoch 71/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726us/step - accuracy: 0.7438 - loss: 0.5281\n",
      "Epoch 72/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847us/step - accuracy: 0.7403 - loss: 0.5325\n",
      "Epoch 73/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 733us/step - accuracy: 0.7381 - loss: 0.5349\n",
      "Epoch 74/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 815us/step - accuracy: 0.7386 - loss: 0.5312\n",
      "Epoch 75/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 736us/step - accuracy: 0.7474 - loss: 0.5247\n",
      "Epoch 76/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - accuracy: 0.7401 - loss: 0.5326\n",
      "Epoch 77/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 830us/step - accuracy: 0.7399 - loss: 0.5320\n",
      "Epoch 78/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 732us/step - accuracy: 0.7455 - loss: 0.5240\n",
      "Epoch 79/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - accuracy: 0.7394 - loss: 0.5317\n",
      "Epoch 80/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 833us/step - accuracy: 0.7405 - loss: 0.5331\n",
      "Epoch 81/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721us/step - accuracy: 0.7435 - loss: 0.5275\n",
      "Epoch 82/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713us/step - accuracy: 0.7400 - loss: 0.5311\n",
      "Epoch 83/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 837us/step - accuracy: 0.7457 - loss: 0.5274\n",
      "Epoch 84/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 724us/step - accuracy: 0.7403 - loss: 0.5274\n",
      "Epoch 85/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 729us/step - accuracy: 0.7408 - loss: 0.5290\n",
      "Epoch 86/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 789us/step - accuracy: 0.7437 - loss: 0.5269\n",
      "Epoch 87/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - accuracy: 0.7471 - loss: 0.5264\n",
      "Epoch 88/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - accuracy: 0.7430 - loss: 0.5296\n",
      "Epoch 89/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847us/step - accuracy: 0.7483 - loss: 0.5219\n",
      "Epoch 90/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713us/step - accuracy: 0.7421 - loss: 0.5285\n",
      "Epoch 91/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 890us/step - accuracy: 0.7432 - loss: 0.5263\n",
      "Epoch 92/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 746us/step - accuracy: 0.7426 - loss: 0.5301\n",
      "Epoch 93/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 724us/step - accuracy: 0.7411 - loss: 0.5332\n",
      "Epoch 94/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841us/step - accuracy: 0.7437 - loss: 0.5270\n",
      "Epoch 95/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 746us/step - accuracy: 0.7420 - loss: 0.5260\n",
      "Epoch 96/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 735us/step - accuracy: 0.7455 - loss: 0.5264\n",
      "Epoch 97/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 864us/step - accuracy: 0.7443 - loss: 0.5254\n",
      "Epoch 98/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 731us/step - accuracy: 0.7438 - loss: 0.5273\n",
      "Epoch 99/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - accuracy: 0.7365 - loss: 0.5323\n",
      "Epoch 100/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 843us/step - accuracy: 0.7455 - loss: 0.5273\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 - 0s - 1ms/step - accuracy: 0.7275 - loss: 0.5691\n",
      "Loss: 0.5690823793411255, Accuracy: 0.7275024056434631\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increase Neurons(n=100,40): 0.7278134226799011\n",
    "### Increase Neurons(n=120,40): 0.7275024056434631\n",
    "### Increase Neurons(n=100,60): 0.7263362407684326"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change Activation Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_142\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_142\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_603 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,720</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_604 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,430</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_605 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_603 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │         \u001b[38;5;34m6,720\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_604 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │         \u001b[38;5;34m2,430\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_605 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m31\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,181</span> (35.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,181\u001b[0m (35.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,181</span> (35.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,181\u001b[0m (35.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "input_features = len(X_train[0])\n",
    "layer1 =  80\n",
    "layer2 = 30\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=layer1, activation=\"relu\", input_dim=input_features))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"relu\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 801us/step - accuracy: 0.6802 - loss: 1.5002\n",
      "Epoch 2/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 907us/step - accuracy: 0.7167 - loss: 1.0852\n",
      "Epoch 3/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 764us/step - accuracy: 0.7113 - loss: 0.9528\n",
      "Epoch 4/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 749us/step - accuracy: 0.6975 - loss: 0.9799\n",
      "Epoch 5/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 741us/step - accuracy: 0.7304 - loss: 0.7589\n",
      "Epoch 6/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 957us/step - accuracy: 0.7293 - loss: 0.7471\n",
      "Epoch 7/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - accuracy: 0.7299 - loss: 0.8465\n",
      "Epoch 8/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 741us/step - accuracy: 0.7196 - loss: 0.7866\n",
      "Epoch 9/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 854us/step - accuracy: 0.7311 - loss: 0.7137\n",
      "Epoch 10/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - accuracy: 0.7255 - loss: 0.7226\n",
      "Epoch 11/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 733us/step - accuracy: 0.7141 - loss: 0.7431\n",
      "Epoch 12/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 834us/step - accuracy: 0.7271 - loss: 0.7283\n",
      "Epoch 13/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 719us/step - accuracy: 0.7269 - loss: 0.7350\n",
      "Epoch 14/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - accuracy: 0.7233 - loss: 0.7098\n",
      "Epoch 15/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 865us/step - accuracy: 0.7370 - loss: 0.7110\n",
      "Epoch 16/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - accuracy: 0.7311 - loss: 0.7210\n",
      "Epoch 17/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - accuracy: 0.7282 - loss: 0.7118\n",
      "Epoch 18/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 844us/step - accuracy: 0.7207 - loss: 0.7142\n",
      "Epoch 19/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 705us/step - accuracy: 0.7259 - loss: 0.6785\n",
      "Epoch 20/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 707us/step - accuracy: 0.7340 - loss: 0.6825\n",
      "Epoch 21/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 832us/step - accuracy: 0.7153 - loss: 0.6686\n",
      "Epoch 22/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - accuracy: 0.7388 - loss: 0.6524\n",
      "Epoch 23/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 725us/step - accuracy: 0.7187 - loss: 0.6615\n",
      "Epoch 24/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 805us/step - accuracy: 0.7224 - loss: 0.6799\n",
      "Epoch 25/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726us/step - accuracy: 0.7252 - loss: 0.6548\n",
      "Epoch 26/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721us/step - accuracy: 0.7315 - loss: 0.6421\n",
      "Epoch 27/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - accuracy: 0.7235 - loss: 0.6488\n",
      "Epoch 28/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 830us/step - accuracy: 0.7265 - loss: 0.6553\n",
      "Epoch 29/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - accuracy: 0.7303 - loss: 0.6453\n",
      "Epoch 30/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 707us/step - accuracy: 0.7339 - loss: 0.6192\n",
      "Epoch 31/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 829us/step - accuracy: 0.6982 - loss: 0.6431\n",
      "Epoch 32/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713us/step - accuracy: 0.7276 - loss: 0.6480\n",
      "Epoch 33/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - accuracy: 0.7317 - loss: 0.6247\n",
      "Epoch 34/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 828us/step - accuracy: 0.7341 - loss: 0.6189\n",
      "Epoch 35/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - accuracy: 0.7322 - loss: 0.6312\n",
      "Epoch 36/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - accuracy: 0.7123 - loss: 0.6195\n",
      "Epoch 37/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 794us/step - accuracy: 0.7279 - loss: 0.6012\n",
      "Epoch 38/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721us/step - accuracy: 0.7326 - loss: 0.5909\n",
      "Epoch 39/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 714us/step - accuracy: 0.7330 - loss: 0.5951\n",
      "Epoch 40/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825us/step - accuracy: 0.7356 - loss: 0.5923\n",
      "Epoch 41/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 718us/step - accuracy: 0.7312 - loss: 0.5934\n",
      "Epoch 42/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - accuracy: 0.7267 - loss: 0.5946\n",
      "Epoch 43/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825us/step - accuracy: 0.7310 - loss: 0.5953\n",
      "Epoch 44/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - accuracy: 0.7361 - loss: 0.5929\n",
      "Epoch 45/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 704us/step - accuracy: 0.7297 - loss: 0.5935\n",
      "Epoch 46/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838us/step - accuracy: 0.7325 - loss: 0.5928\n",
      "Epoch 47/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 719us/step - accuracy: 0.7324 - loss: 0.6038\n",
      "Epoch 48/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - accuracy: 0.7254 - loss: 0.6051\n",
      "Epoch 49/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 830us/step - accuracy: 0.7332 - loss: 0.5990\n",
      "Epoch 50/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - accuracy: 0.7346 - loss: 0.5852\n",
      "Epoch 51/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 723us/step - accuracy: 0.7258 - loss: 0.6018\n",
      "Epoch 52/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 740us/step - accuracy: 0.7365 - loss: 0.5836\n",
      "Epoch 53/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 749us/step - accuracy: 0.7318 - loss: 0.5978\n",
      "Epoch 54/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - accuracy: 0.7350 - loss: 0.5912\n",
      "Epoch 55/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 719us/step - accuracy: 0.7103 - loss: 0.6073\n",
      "Epoch 56/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 830us/step - accuracy: 0.7329 - loss: 0.6211\n",
      "Epoch 57/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 704us/step - accuracy: 0.7339 - loss: 0.6072\n",
      "Epoch 58/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 702us/step - accuracy: 0.7321 - loss: 0.6172\n",
      "Epoch 59/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838us/step - accuracy: 0.7350 - loss: 0.6086\n",
      "Epoch 60/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 705us/step - accuracy: 0.7337 - loss: 0.6161\n",
      "Epoch 61/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - accuracy: 0.7331 - loss: 0.5842\n",
      "Epoch 62/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 854us/step - accuracy: 0.7386 - loss: 0.6002\n",
      "Epoch 63/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - accuracy: 0.7349 - loss: 0.5929\n",
      "Epoch 64/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 707us/step - accuracy: 0.7379 - loss: 0.5936\n",
      "Epoch 65/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 820us/step - accuracy: 0.7322 - loss: 0.5891\n",
      "Epoch 66/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713us/step - accuracy: 0.7304 - loss: 0.5992\n",
      "Epoch 67/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - accuracy: 0.7330 - loss: 0.6058\n",
      "Epoch 68/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 829us/step - accuracy: 0.7338 - loss: 0.5893\n",
      "Epoch 69/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - accuracy: 0.7338 - loss: 0.5903\n",
      "Epoch 70/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 719us/step - accuracy: 0.7392 - loss: 0.5864\n",
      "Epoch 71/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 848us/step - accuracy: 0.7271 - loss: 0.5975\n",
      "Epoch 72/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 719us/step - accuracy: 0.7368 - loss: 0.5777\n",
      "Epoch 73/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 734us/step - accuracy: 0.7339 - loss: 0.5869\n",
      "Epoch 74/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 730us/step - accuracy: 0.7376 - loss: 0.5908\n",
      "Epoch 75/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726us/step - accuracy: 0.7339 - loss: 0.5895\n",
      "Epoch 76/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 826us/step - accuracy: 0.7339 - loss: 0.6046\n",
      "Epoch 77/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 766us/step - accuracy: 0.7372 - loss: 0.5889\n",
      "Epoch 78/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 742us/step - accuracy: 0.7380 - loss: 0.6042\n",
      "Epoch 79/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877us/step - accuracy: 0.7355 - loss: 0.5928\n",
      "Epoch 80/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 754us/step - accuracy: 0.7374 - loss: 0.6064\n",
      "Epoch 81/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 740us/step - accuracy: 0.7316 - loss: 0.6101\n",
      "Epoch 82/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 822us/step - accuracy: 0.7435 - loss: 0.5936\n",
      "Epoch 83/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 740us/step - accuracy: 0.7208 - loss: 0.6051\n",
      "Epoch 84/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 750us/step - accuracy: 0.7406 - loss: 0.5980\n",
      "Epoch 85/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 929us/step - accuracy: 0.7327 - loss: 0.6005\n",
      "Epoch 86/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 753us/step - accuracy: 0.7400 - loss: 0.5855\n",
      "Epoch 87/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 878us/step - accuracy: 0.7396 - loss: 0.5913\n",
      "Epoch 88/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 740us/step - accuracy: 0.7352 - loss: 0.5935\n",
      "Epoch 89/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 738us/step - accuracy: 0.7293 - loss: 0.6050\n",
      "Epoch 90/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 0.7313 - loss: 0.6033\n",
      "Epoch 91/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 759us/step - accuracy: 0.7372 - loss: 0.5951\n",
      "Epoch 92/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 749us/step - accuracy: 0.7300 - loss: 0.6008\n",
      "Epoch 93/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 879us/step - accuracy: 0.7400 - loss: 0.5848\n",
      "Epoch 94/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 736us/step - accuracy: 0.7372 - loss: 0.5969\n",
      "Epoch 95/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841us/step - accuracy: 0.7339 - loss: 0.6054\n",
      "Epoch 96/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 738us/step - accuracy: 0.7404 - loss: 0.5900\n",
      "Epoch 97/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 731us/step - accuracy: 0.7133 - loss: 0.6451\n",
      "Epoch 98/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877us/step - accuracy: 0.7246 - loss: 0.5961\n",
      "Epoch 99/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 724us/step - accuracy: 0.7357 - loss: 0.5781\n",
      "Epoch 100/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 708us/step - accuracy: 0.7358 - loss: 0.5957\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 - 0s - 1ms/step - accuracy: 0.7304 - loss: 0.6303\n",
      "Loss: 0.6303449273109436, Accuracy: 0.7304179072380066\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change Activation Functions(f=\"relu\",\"relu\",\"tanh\"): 0.7296404242515564\n",
    "### Change Activation Functions(f=\"relu\",\"relu\",\"relu\"): 0.7304179072380066"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Attempt at Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rmt20\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,360</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">820</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │         \u001b[38;5;34m3,360\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m820\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m210\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m11\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,401</span> (17.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,401\u001b[0m (17.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,401</span> (17.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,401\u001b[0m (17.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "input_features = len(X_train[0])\n",
    "layer1 = 40\n",
    "layer2 = 20\n",
    "layer3 = 10\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=layer1, activation=\"leaky_relu\", input_dim=input_features))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=layer2, activation=\"leaky_relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=layer3, activation=\"leaky_relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 867us/step - accuracy: 0.6945 - loss: 0.6017\n",
      "Epoch 2/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 984us/step - accuracy: 0.7319 - loss: 0.5513\n",
      "Epoch 3/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 932us/step - accuracy: 0.7316 - loss: 0.5512\n",
      "Epoch 4/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 795us/step - accuracy: 0.7321 - loss: 0.5467\n",
      "Epoch 5/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 874us/step - accuracy: 0.7339 - loss: 0.5440\n",
      "Epoch 6/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 753us/step - accuracy: 0.7355 - loss: 0.5420\n",
      "Epoch 7/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 781us/step - accuracy: 0.7376 - loss: 0.5394\n",
      "Epoch 8/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 739us/step - accuracy: 0.7400 - loss: 0.5390\n",
      "Epoch 9/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 748us/step - accuracy: 0.7403 - loss: 0.5376\n",
      "Epoch 10/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 736us/step - accuracy: 0.7401 - loss: 0.5371\n",
      "Epoch 11/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 760us/step - accuracy: 0.7395 - loss: 0.5390\n",
      "Epoch 12/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 747us/step - accuracy: 0.7379 - loss: 0.5385\n",
      "Epoch 13/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 742us/step - accuracy: 0.7329 - loss: 0.5431\n",
      "Epoch 14/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 885us/step - accuracy: 0.7368 - loss: 0.5409\n",
      "Epoch 15/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877us/step - accuracy: 0.7423 - loss: 0.5377\n",
      "Epoch 16/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 748us/step - accuracy: 0.7292 - loss: 0.5454\n",
      "Epoch 17/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 775us/step - accuracy: 0.7339 - loss: 0.5426\n",
      "Epoch 18/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 734us/step - accuracy: 0.7411 - loss: 0.5353\n",
      "Epoch 19/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 720us/step - accuracy: 0.7365 - loss: 0.5404\n",
      "Epoch 20/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - accuracy: 0.7341 - loss: 0.5421\n",
      "Epoch 21/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 720us/step - accuracy: 0.7424 - loss: 0.5346\n",
      "Epoch 22/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 763us/step - accuracy: 0.7416 - loss: 0.5361\n",
      "Epoch 23/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 772us/step - accuracy: 0.7393 - loss: 0.5369\n",
      "Epoch 24/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825us/step - accuracy: 0.7349 - loss: 0.5408\n",
      "Epoch 25/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 881us/step - accuracy: 0.7408 - loss: 0.5362\n",
      "Epoch 26/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 846us/step - accuracy: 0.7398 - loss: 0.5376\n",
      "Epoch 27/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 769us/step - accuracy: 0.7404 - loss: 0.5347\n",
      "Epoch 28/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 727us/step - accuracy: 0.7381 - loss: 0.5389\n",
      "Epoch 29/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 824us/step - accuracy: 0.7350 - loss: 0.5429\n",
      "Epoch 30/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 816us/step - accuracy: 0.7382 - loss: 0.5368\n",
      "Epoch 31/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 853us/step - accuracy: 0.7395 - loss: 0.5342\n",
      "Epoch 32/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877us/step - accuracy: 0.7358 - loss: 0.5419\n",
      "Epoch 33/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7360 - loss: 0.5393\n",
      "Epoch 34/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7401 - loss: 0.5341\n",
      "Epoch 35/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 968us/step - accuracy: 0.7355 - loss: 0.5389\n",
      "Epoch 36/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 870us/step - accuracy: 0.7341 - loss: 0.5422\n",
      "Epoch 37/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 799us/step - accuracy: 0.7408 - loss: 0.5347\n",
      "Epoch 38/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 803us/step - accuracy: 0.7331 - loss: 0.5395\n",
      "Epoch 39/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 728us/step - accuracy: 0.7426 - loss: 0.5300\n",
      "Epoch 40/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 704us/step - accuracy: 0.7401 - loss: 0.5359\n",
      "Epoch 41/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 708us/step - accuracy: 0.7400 - loss: 0.5325\n",
      "Epoch 42/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - accuracy: 0.7372 - loss: 0.5402\n",
      "Epoch 43/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 815us/step - accuracy: 0.7380 - loss: 0.5349\n",
      "Epoch 44/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - accuracy: 0.7343 - loss: 0.5385\n",
      "Epoch 45/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 746us/step - accuracy: 0.7385 - loss: 0.5371\n",
      "Epoch 46/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 739us/step - accuracy: 0.7410 - loss: 0.5350\n",
      "Epoch 47/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 729us/step - accuracy: 0.7406 - loss: 0.5326\n",
      "Epoch 48/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - accuracy: 0.7378 - loss: 0.5356\n",
      "Epoch 49/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 739us/step - accuracy: 0.7430 - loss: 0.5291\n",
      "Epoch 50/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 704us/step - accuracy: 0.7335 - loss: 0.5382\n",
      "Epoch 51/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 702us/step - accuracy: 0.7376 - loss: 0.5355\n",
      "Epoch 52/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 708us/step - accuracy: 0.7359 - loss: 0.5386\n",
      "Epoch 53/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726us/step - accuracy: 0.7396 - loss: 0.5344\n",
      "Epoch 54/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 696us/step - accuracy: 0.7359 - loss: 0.5378\n",
      "Epoch 55/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 708us/step - accuracy: 0.7446 - loss: 0.5285\n",
      "Epoch 56/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721us/step - accuracy: 0.7440 - loss: 0.5340\n",
      "Epoch 57/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 751us/step - accuracy: 0.7396 - loss: 0.5355\n",
      "Epoch 58/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 703us/step - accuracy: 0.7409 - loss: 0.5344\n",
      "Epoch 59/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 731us/step - accuracy: 0.7364 - loss: 0.5375\n",
      "Epoch 60/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - accuracy: 0.7386 - loss: 0.5376\n",
      "Epoch 61/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 696us/step - accuracy: 0.7392 - loss: 0.5349\n",
      "Epoch 62/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 680us/step - accuracy: 0.7381 - loss: 0.5393\n",
      "Epoch 63/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - accuracy: 0.7438 - loss: 0.5295\n",
      "Epoch 64/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 692us/step - accuracy: 0.7385 - loss: 0.5355\n",
      "Epoch 65/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 691us/step - accuracy: 0.7373 - loss: 0.5367\n",
      "Epoch 66/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 674us/step - accuracy: 0.7388 - loss: 0.5357\n",
      "Epoch 67/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - accuracy: 0.7394 - loss: 0.5339\n",
      "Epoch 68/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 692us/step - accuracy: 0.7384 - loss: 0.5351\n",
      "Epoch 69/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 689us/step - accuracy: 0.7384 - loss: 0.5375\n",
      "Epoch 70/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 702us/step - accuracy: 0.7443 - loss: 0.5299\n",
      "Epoch 71/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 870us/step - accuracy: 0.7376 - loss: 0.5350\n",
      "Epoch 72/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7387 - loss: 0.5374\n",
      "Epoch 73/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 795us/step - accuracy: 0.7401 - loss: 0.5352\n",
      "Epoch 74/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - accuracy: 0.7432 - loss: 0.5322\n",
      "Epoch 75/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721us/step - accuracy: 0.7430 - loss: 0.5300\n",
      "Epoch 76/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 750us/step - accuracy: 0.7436 - loss: 0.5338\n",
      "Epoch 77/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 734us/step - accuracy: 0.7376 - loss: 0.5369\n",
      "Epoch 78/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 697us/step - accuracy: 0.7405 - loss: 0.5359\n",
      "Epoch 79/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 748us/step - accuracy: 0.7440 - loss: 0.5307\n",
      "Epoch 80/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - accuracy: 0.7434 - loss: 0.5294\n",
      "Epoch 81/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 741us/step - accuracy: 0.7379 - loss: 0.5345\n",
      "Epoch 82/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - accuracy: 0.7424 - loss: 0.5324\n",
      "Epoch 83/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 722us/step - accuracy: 0.7382 - loss: 0.5375\n",
      "Epoch 84/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 751us/step - accuracy: 0.7425 - loss: 0.5292\n",
      "Epoch 85/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 744us/step - accuracy: 0.7411 - loss: 0.5286\n",
      "Epoch 86/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 703us/step - accuracy: 0.7424 - loss: 0.5301\n",
      "Epoch 87/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 771us/step - accuracy: 0.7397 - loss: 0.5332\n",
      "Epoch 88/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 728us/step - accuracy: 0.7385 - loss: 0.5336\n",
      "Epoch 89/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - accuracy: 0.7440 - loss: 0.5314\n",
      "Epoch 90/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 718us/step - accuracy: 0.7415 - loss: 0.5306\n",
      "Epoch 91/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - accuracy: 0.7409 - loss: 0.5338\n",
      "Epoch 92/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 698us/step - accuracy: 0.7398 - loss: 0.5360\n",
      "Epoch 93/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 770us/step - accuracy: 0.7403 - loss: 0.5344\n",
      "Epoch 94/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 681us/step - accuracy: 0.7412 - loss: 0.5330\n",
      "Epoch 95/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 702us/step - accuracy: 0.7411 - loss: 0.5302\n",
      "Epoch 96/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 701us/step - accuracy: 0.7402 - loss: 0.5333\n",
      "Epoch 97/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 758us/step - accuracy: 0.7401 - loss: 0.5306\n",
      "Epoch 98/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 695us/step - accuracy: 0.7437 - loss: 0.5312\n",
      "Epoch 99/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - accuracy: 0.7429 - loss: 0.5306\n",
      "Epoch 100/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 690us/step - accuracy: 0.7396 - loss: 0.5345\n",
      "Epoch 101/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 722us/step - accuracy: 0.7399 - loss: 0.5368\n",
      "Epoch 102/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 770us/step - accuracy: 0.7414 - loss: 0.5330\n",
      "Epoch 103/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 724us/step - accuracy: 0.7428 - loss: 0.5285\n",
      "Epoch 104/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 718us/step - accuracy: 0.7405 - loss: 0.5340\n",
      "Epoch 105/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694us/step - accuracy: 0.7436 - loss: 0.5285\n",
      "Epoch 106/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671us/step - accuracy: 0.7366 - loss: 0.5380\n",
      "Epoch 107/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 705us/step - accuracy: 0.7401 - loss: 0.5329\n",
      "Epoch 108/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671us/step - accuracy: 0.7393 - loss: 0.5339\n",
      "Epoch 109/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - accuracy: 0.7408 - loss: 0.5311\n",
      "Epoch 110/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 689us/step - accuracy: 0.7449 - loss: 0.5265\n",
      "Epoch 111/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - accuracy: 0.7378 - loss: 0.5350\n",
      "Epoch 112/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 707us/step - accuracy: 0.7376 - loss: 0.5342\n",
      "Epoch 113/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712us/step - accuracy: 0.7403 - loss: 0.5324\n",
      "Epoch 114/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 686us/step - accuracy: 0.7398 - loss: 0.5321\n",
      "Epoch 115/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 724us/step - accuracy: 0.7407 - loss: 0.5316\n",
      "Epoch 116/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - accuracy: 0.7404 - loss: 0.5342\n",
      "Epoch 117/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712us/step - accuracy: 0.7381 - loss: 0.5344\n",
      "Epoch 118/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669us/step - accuracy: 0.7382 - loss: 0.5353\n",
      "Epoch 119/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 688us/step - accuracy: 0.7398 - loss: 0.5315\n",
      "Epoch 120/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 695us/step - accuracy: 0.7406 - loss: 0.5347\n",
      "Epoch 121/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 697us/step - accuracy: 0.7427 - loss: 0.5250\n",
      "Epoch 122/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 714us/step - accuracy: 0.7415 - loss: 0.5303\n",
      "Epoch 123/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 720us/step - accuracy: 0.7405 - loss: 0.5349\n",
      "Epoch 124/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694us/step - accuracy: 0.7404 - loss: 0.5338\n",
      "Epoch 125/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 696us/step - accuracy: 0.7369 - loss: 0.5369\n",
      "Epoch 126/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847us/step - accuracy: 0.7457 - loss: 0.5272\n",
      "Epoch 127/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 868us/step - accuracy: 0.7441 - loss: 0.5293\n",
      "Epoch 128/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 868us/step - accuracy: 0.7421 - loss: 0.5290\n",
      "Epoch 129/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 786us/step - accuracy: 0.7397 - loss: 0.5332\n",
      "Epoch 130/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 753us/step - accuracy: 0.7416 - loss: 0.5314\n",
      "Epoch 131/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 720us/step - accuracy: 0.7390 - loss: 0.5331\n",
      "Epoch 132/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 896us/step - accuracy: 0.7380 - loss: 0.5342\n",
      "Epoch 133/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 759us/step - accuracy: 0.7401 - loss: 0.5302\n",
      "Epoch 134/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 738us/step - accuracy: 0.7409 - loss: 0.5315\n",
      "Epoch 135/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 793us/step - accuracy: 0.7395 - loss: 0.5335\n",
      "Epoch 136/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 819us/step - accuracy: 0.7391 - loss: 0.5334\n",
      "Epoch 137/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877us/step - accuracy: 0.7428 - loss: 0.5316\n",
      "Epoch 138/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851us/step - accuracy: 0.7420 - loss: 0.5292\n",
      "Epoch 139/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 941us/step - accuracy: 0.7453 - loss: 0.5274\n",
      "Epoch 140/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7416 - loss: 0.5297\n",
      "Epoch 141/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7403 - loss: 0.5336\n",
      "Epoch 142/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 865us/step - accuracy: 0.7456 - loss: 0.5249\n",
      "Epoch 143/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 880us/step - accuracy: 0.7432 - loss: 0.5302\n",
      "Epoch 144/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 875us/step - accuracy: 0.7439 - loss: 0.5281\n",
      "Epoch 145/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 839us/step - accuracy: 0.7423 - loss: 0.5290\n",
      "Epoch 146/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 862us/step - accuracy: 0.7426 - loss: 0.5301\n",
      "Epoch 147/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 904us/step - accuracy: 0.7377 - loss: 0.5340\n",
      "Epoch 148/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 836us/step - accuracy: 0.7406 - loss: 0.5318\n",
      "Epoch 149/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 823us/step - accuracy: 0.7401 - loss: 0.5310\n",
      "Epoch 150/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841us/step - accuracy: 0.7461 - loss: 0.5306\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 - 0s - 1ms/step - accuracy: 0.7293 - loss: 0.5547\n",
      "Loss: 0.554726779460907, Accuracy: 0.7292516827583313\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=h5\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Export our model to HDF5 file\n",
    "nn.save(\"AlphabetSoupCharity_Optimization.h5\", save_format='h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at Training History Here\n",
    "### Run desired model beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a DataFrame containing training history\n",
    "history_df = pd.DataFrame(fit_model.history)\n",
    "\n",
    "# Increase the index by 1 to match the number of epochs\n",
    "history_df.index += 1\n",
    "\n",
    "# Plot the graphs\n",
    "history_df.plot(y=\"loss\")\n",
    "history_df.plot(y=\"accuracy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
