{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "#  Import and read the charity_data.csv.\n",
    "import pandas as pd\n",
    "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34294</th>\n",
       "      <td>T4</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34295</th>\n",
       "      <td>T4</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34296</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34297</th>\n",
       "      <td>T5</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34298</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1M-5M</td>\n",
       "      <td>N</td>\n",
       "      <td>36500179</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34299 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0                  T10       Independent          C1000    ProductDev   \n",
       "1                   T3       Independent          C2000  Preservation   \n",
       "2                   T5  CompanySponsored          C3000    ProductDev   \n",
       "3                   T3  CompanySponsored          C2000  Preservation   \n",
       "4                   T3       Independent          C1000     Heathcare   \n",
       "...                ...               ...            ...           ...   \n",
       "34294               T4       Independent          C1000    ProductDev   \n",
       "34295               T4  CompanySponsored          C3000    ProductDev   \n",
       "34296               T3  CompanySponsored          C2000  Preservation   \n",
       "34297               T5       Independent          C3000    ProductDev   \n",
       "34298               T3       Independent          C1000  Preservation   \n",
       "\n",
       "       ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS   ASK_AMT  \\\n",
       "0       Association       1              0                      N      5000   \n",
       "1      Co-operative       1         1-9999                      N    108590   \n",
       "2       Association       1              0                      N      5000   \n",
       "3             Trust       1    10000-24999                      N      6692   \n",
       "4             Trust       1  100000-499999                      N    142590   \n",
       "...             ...     ...            ...                    ...       ...   \n",
       "34294   Association       1              0                      N      5000   \n",
       "34295   Association       1              0                      N      5000   \n",
       "34296   Association       1              0                      N      5000   \n",
       "34297   Association       1              0                      N      5000   \n",
       "34298  Co-operative       1          1M-5M                      N  36500179   \n",
       "\n",
       "       IS_SUCCESSFUL  \n",
       "0                  1  \n",
       "1                  1  \n",
       "2                  0  \n",
       "3                  1  \n",
       "4                  1  \n",
       "...              ...  \n",
       "34294              0  \n",
       "34295              0  \n",
       "34296              0  \n",
       "34297              1  \n",
       "34298              0  \n",
       "\n",
       "[34299 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
    "application_df.drop(columns=[\"EIN\", \"NAME\"],inplace=True)\n",
    "application_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE            17\n",
       "AFFILIATION                  6\n",
       "CLASSIFICATION              71\n",
       "USE_CASE                     5\n",
       "ORGANIZATION                 4\n",
       "STATUS                       2\n",
       "INCOME_AMT                   9\n",
       "SPECIAL_CONSIDERATIONS       2\n",
       "ASK_AMT                   8747\n",
       "IS_SUCCESSFUL                2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of unique values in each column.\n",
    "application_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE\n",
       "T3     27037\n",
       "T4      1542\n",
       "T6      1216\n",
       "T5      1173\n",
       "T19     1065\n",
       "T8       737\n",
       "T7       725\n",
       "T10      528\n",
       "T9       156\n",
       "T13       66\n",
       "T12       27\n",
       "T2        16\n",
       "T25        3\n",
       "T14        3\n",
       "T29        2\n",
       "T15        2\n",
       "T17        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at APPLICATION_TYPE value counts to identify and replace with \"Other\"\n",
    "app_count = application_df[\"APPLICATION_TYPE\"].value_counts()\n",
    "app_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE\n",
       "T3       27037\n",
       "T4        1542\n",
       "T6        1216\n",
       "T5        1173\n",
       "T19       1065\n",
       "T8         737\n",
       "T7         725\n",
       "T10        528\n",
       "Other      276\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of application types to be replaced\n",
    "# use the variable name `application_types_to_replace`\n",
    "application_types_to_replace = app_count.index[8:]\n",
    "\n",
    "# Replace in dataframe\n",
    "for app in application_types_to_replace:\n",
    "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
    "\n",
    "# Check to make sure replacement was successful\n",
    "application_df['APPLICATION_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLASSIFICATION\n",
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "         ...  \n",
       "C4120        1\n",
       "C8210        1\n",
       "C2561        1\n",
       "C4500        1\n",
       "C2150        1\n",
       "Name: count, Length: 71, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at CLASSIFICATION value counts to identify and replace with \"Other\"\n",
    "class_count = application_df[\"CLASSIFICATION\"].value_counts()\n",
    "class_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLASSIFICATION\n",
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "C7000      777\n",
       "C1700      287\n",
       "C4000      194\n",
       "C5000      116\n",
       "C1270      114\n",
       "C2700      104\n",
       "C2800       95\n",
       "C7100       75\n",
       "C1300       58\n",
       "C1280       50\n",
       "C1230       36\n",
       "C1400       34\n",
       "C7200       32\n",
       "C2300       32\n",
       "C1240       30\n",
       "C8000       20\n",
       "C7120       18\n",
       "C1500       16\n",
       "C1800       15\n",
       "C6000       15\n",
       "C1250       14\n",
       "C8200       11\n",
       "C1238       10\n",
       "C1278       10\n",
       "C1235        9\n",
       "C1237        9\n",
       "C7210        7\n",
       "C2400        6\n",
       "C1720        6\n",
       "C4100        6\n",
       "C1257        5\n",
       "C1600        5\n",
       "C1260        3\n",
       "C2710        3\n",
       "C0           3\n",
       "C3200        2\n",
       "C1234        2\n",
       "C1246        2\n",
       "C1267        2\n",
       "C1256        2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You may find it helpful to look at CLASSIFICATION value counts > 1\n",
    "class_count[class_count > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLASSIFICATION\n",
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "C7000      777\n",
       "C1700      287\n",
       "C4000      194\n",
       "C5000      116\n",
       "C1270      114\n",
       "C2700      104\n",
       "C2800       95\n",
       "C7100       75\n",
       "C1300       58\n",
       "C1280       50\n",
       "C1230       36\n",
       "C1400       34\n",
       "C7200       32\n",
       "C2300       32\n",
       "C1240       30\n",
       "Other       26\n",
       "C8000       20\n",
       "C7120       18\n",
       "C1500       16\n",
       "C6000       15\n",
       "C1800       15\n",
       "C1250       14\n",
       "C8200       11\n",
       "C1238       10\n",
       "C1278       10\n",
       "C1237        9\n",
       "C1235        9\n",
       "C7210        7\n",
       "C1720        6\n",
       "C2400        6\n",
       "C4100        6\n",
       "C1257        5\n",
       "C1600        5\n",
       "C1260        3\n",
       "C2710        3\n",
       "C0           3\n",
       "C1267        2\n",
       "C1256        2\n",
       "C1234        2\n",
       "C1246        2\n",
       "C3200        2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of classifications to be replaced\n",
    "# use the variable name `classifications_to_replace`\n",
    "classifications_to_replace = class_count[class_count < 2].index\n",
    "\n",
    "# Replace in dataframe\n",
    "for cls in classifications_to_replace:\n",
    "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
    "\n",
    "# Check to make sure replacement was successful\n",
    "application_df['CLASSIFICATION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34299 entries, 0 to 34298\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   APPLICATION_TYPE        34299 non-null  object\n",
      " 1   AFFILIATION             34299 non-null  object\n",
      " 2   CLASSIFICATION          34299 non-null  object\n",
      " 3   USE_CASE                34299 non-null  object\n",
      " 4   ORGANIZATION            34299 non-null  object\n",
      " 5   STATUS                  34299 non-null  int64 \n",
      " 6   INCOME_AMT              34299 non-null  object\n",
      " 7   SPECIAL_CONSIDERATIONS  34299 non-null  object\n",
      " 8   ASK_AMT                 34299 non-null  int64 \n",
      " 9   IS_SUCCESSFUL           34299 non-null  int64 \n",
      "dtypes: int64(3), object(7)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "application_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34294</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34295</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34296</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34297</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34298</th>\n",
       "      <td>1</td>\n",
       "      <td>36500179</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34299 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       STATUS   ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
       "0           1      5000              1                   False   \n",
       "1           1    108590              1                   False   \n",
       "2           1      5000              0                   False   \n",
       "3           1      6692              1                   False   \n",
       "4           1    142590              1                   False   \n",
       "...       ...       ...            ...                     ...   \n",
       "34294       1      5000              0                   False   \n",
       "34295       1      5000              0                   False   \n",
       "34296       1      5000              0                   False   \n",
       "34297       1      5000              1                   False   \n",
       "34298       1  36500179              0                   False   \n",
       "\n",
       "       APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  \\\n",
       "0                      True                 False                False   \n",
       "1                     False                 False                 True   \n",
       "2                     False                 False                False   \n",
       "3                     False                 False                 True   \n",
       "4                     False                 False                 True   \n",
       "...                     ...                   ...                  ...   \n",
       "34294                 False                 False                False   \n",
       "34295                 False                 False                False   \n",
       "34296                 False                 False                 True   \n",
       "34297                 False                 False                False   \n",
       "34298                 False                 False                 True   \n",
       "\n",
       "       APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  ...  \\\n",
       "0                    False                False                False  ...   \n",
       "1                    False                False                False  ...   \n",
       "2                    False                 True                False  ...   \n",
       "3                    False                False                False  ...   \n",
       "4                    False                False                False  ...   \n",
       "...                    ...                  ...                  ...  ...   \n",
       "34294                 True                False                False  ...   \n",
       "34295                 True                False                False  ...   \n",
       "34296                False                False                False  ...   \n",
       "34297                False                 True                False  ...   \n",
       "34298                False                False                False  ...   \n",
       "\n",
       "       INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0                  False                   False                     False   \n",
       "1                   True                   False                     False   \n",
       "2                  False                   False                     False   \n",
       "3                  False                    True                     False   \n",
       "4                  False                   False                      True   \n",
       "...                  ...                     ...                       ...   \n",
       "34294              False                   False                     False   \n",
       "34295              False                   False                     False   \n",
       "34296              False                   False                     False   \n",
       "34297              False                   False                     False   \n",
       "34298              False                   False                     False   \n",
       "\n",
       "       INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                   False             False                   False   \n",
       "1                   False             False                   False   \n",
       "2                   False             False                   False   \n",
       "3                   False             False                   False   \n",
       "4                   False             False                   False   \n",
       "...                   ...               ...                     ...   \n",
       "34294               False             False                   False   \n",
       "34295               False             False                   False   \n",
       "34296               False             False                   False   \n",
       "34297               False             False                   False   \n",
       "34298               False              True                   False   \n",
       "\n",
       "       INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0                False              False                      True   \n",
       "1                False              False                      True   \n",
       "2                False              False                      True   \n",
       "3                False              False                      True   \n",
       "4                False              False                      True   \n",
       "...                ...                ...                       ...   \n",
       "34294            False              False                      True   \n",
       "34295            False              False                      True   \n",
       "34296            False              False                      True   \n",
       "34297            False              False                      True   \n",
       "34298            False              False                      True   \n",
       "\n",
       "       SPECIAL_CONSIDERATIONS_Y  \n",
       "0                         False  \n",
       "1                         False  \n",
       "2                         False  \n",
       "3                         False  \n",
       "4                         False  \n",
       "...                         ...  \n",
       "34294                     False  \n",
       "34295                     False  \n",
       "34296                     False  \n",
       "34297                     False  \n",
       "34298                     False  \n",
       "\n",
       "[34299 rows x 84 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical data to numeric with `pd.get_dummies`\n",
    "application_dummies_df = pd.get_dummies(application_df[[\"APPLICATION_TYPE\",\"AFFILIATION\",\"CLASSIFICATION\",\"USE_CASE\",\"ORGANIZATION\",\"INCOME_AMT\",\"SPECIAL_CONSIDERATIONS\"]])\n",
    "application_df.drop(columns=[\"APPLICATION_TYPE\",\"AFFILIATION\",\"CLASSIFICATION\",\"USE_CASE\",\"ORGANIZATION\",\"INCOME_AMT\",\"SPECIAL_CONSIDERATIONS\"],inplace=True)\n",
    "application_dummies_df = pd.merge(application_df, application_dummies_df, how=\"inner\",left_index=True,right_index=True)\n",
    "application_dummies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = application_dummies_df['IS_SUCCESSFUL']\n",
    "\n",
    "# Separate the X variable, the features\n",
    "X = application_dummies_df.drop(columns=['IS_SUCCESSFUL']).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,random_state=1,train_size=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile, Train and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rmt20\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,720</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,430</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │         \u001b[38;5;34m6,720\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │         \u001b[38;5;34m2,430\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m31\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,181</span> (35.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,181\u001b[0m (35.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,181</span> (35.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,181\u001b[0m (35.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "input_features = len(X_train[0])\n",
    "layer1 =  80\n",
    "layer2 = 30\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=layer1, activation=\"relu\", input_dim=input_features))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 737us/step - accuracy: 0.7006 - loss: 0.5882\n",
      "Epoch 2/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - accuracy: 0.7299 - loss: 0.5550\n",
      "Epoch 3/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 719us/step - accuracy: 0.7301 - loss: 0.5505\n",
      "Epoch 4/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 728us/step - accuracy: 0.7350 - loss: 0.5498\n",
      "Epoch 5/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 700us/step - accuracy: 0.7322 - loss: 0.5497\n",
      "Epoch 6/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712us/step - accuracy: 0.7360 - loss: 0.5445\n",
      "Epoch 7/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 832us/step - accuracy: 0.7350 - loss: 0.5466\n",
      "Epoch 8/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 776us/step - accuracy: 0.7330 - loss: 0.5451\n",
      "Epoch 9/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 730us/step - accuracy: 0.7356 - loss: 0.5450\n",
      "Epoch 10/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 828us/step - accuracy: 0.7327 - loss: 0.5452\n",
      "Epoch 11/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - accuracy: 0.7321 - loss: 0.5493\n",
      "Epoch 12/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 741us/step - accuracy: 0.7368 - loss: 0.5414\n",
      "Epoch 13/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 969us/step - accuracy: 0.7398 - loss: 0.5406\n",
      "Epoch 14/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 760us/step - accuracy: 0.7338 - loss: 0.5459\n",
      "Epoch 15/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 831us/step - accuracy: 0.7314 - loss: 0.5471\n",
      "Epoch 16/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712us/step - accuracy: 0.7362 - loss: 0.5450\n",
      "Epoch 17/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 837us/step - accuracy: 0.7335 - loss: 0.5413\n",
      "Epoch 18/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 760us/step - accuracy: 0.7390 - loss: 0.5421\n",
      "Epoch 19/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 757us/step - accuracy: 0.7317 - loss: 0.5442\n",
      "Epoch 20/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 850us/step - accuracy: 0.7331 - loss: 0.5445\n",
      "Epoch 21/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 744us/step - accuracy: 0.7363 - loss: 0.5424\n",
      "Epoch 22/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 714us/step - accuracy: 0.7352 - loss: 0.5437\n",
      "Epoch 23/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847us/step - accuracy: 0.7417 - loss: 0.5351\n",
      "Epoch 24/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 738us/step - accuracy: 0.7390 - loss: 0.5378\n",
      "Epoch 25/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 772us/step - accuracy: 0.7337 - loss: 0.5385\n",
      "Epoch 26/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 863us/step - accuracy: 0.7349 - loss: 0.5418\n",
      "Epoch 27/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 733us/step - accuracy: 0.7367 - loss: 0.5430\n",
      "Epoch 28/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 801us/step - accuracy: 0.7408 - loss: 0.5383\n",
      "Epoch 29/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 727us/step - accuracy: 0.7403 - loss: 0.5359\n",
      "Epoch 30/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 718us/step - accuracy: 0.7393 - loss: 0.5346\n",
      "Epoch 31/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 859us/step - accuracy: 0.7384 - loss: 0.5378\n",
      "Epoch 32/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 719us/step - accuracy: 0.7369 - loss: 0.5396\n",
      "Epoch 33/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 680us/step - accuracy: 0.7384 - loss: 0.5415\n",
      "Epoch 34/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 788us/step - accuracy: 0.7347 - loss: 0.5391\n",
      "Epoch 35/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671us/step - accuracy: 0.7334 - loss: 0.5414\n",
      "Epoch 36/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 674us/step - accuracy: 0.7376 - loss: 0.5411\n",
      "Epoch 37/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 766us/step - accuracy: 0.7391 - loss: 0.5348\n",
      "Epoch 38/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 678us/step - accuracy: 0.7365 - loss: 0.5385\n",
      "Epoch 39/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 745us/step - accuracy: 0.7441 - loss: 0.5334\n",
      "Epoch 40/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7344 - loss: 0.5467\n",
      "Epoch 41/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 791us/step - accuracy: 0.7450 - loss: 0.5314\n",
      "Epoch 42/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 796us/step - accuracy: 0.7415 - loss: 0.5363\n",
      "Epoch 43/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 773us/step - accuracy: 0.7414 - loss: 0.5374\n",
      "Epoch 44/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 900us/step - accuracy: 0.7385 - loss: 0.5363\n",
      "Epoch 45/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - accuracy: 0.7392 - loss: 0.5345\n",
      "Epoch 46/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 787us/step - accuracy: 0.7365 - loss: 0.5384\n",
      "Epoch 47/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 675us/step - accuracy: 0.7396 - loss: 0.5359\n",
      "Epoch 48/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 765us/step - accuracy: 0.7396 - loss: 0.5384\n",
      "Epoch 49/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 884us/step - accuracy: 0.7428 - loss: 0.5356\n",
      "Epoch 50/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 760us/step - accuracy: 0.7375 - loss: 0.5382\n",
      "Epoch 51/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 764us/step - accuracy: 0.7367 - loss: 0.5404\n",
      "Epoch 52/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 972us/step - accuracy: 0.7407 - loss: 0.5339\n",
      "Epoch 53/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 762us/step - accuracy: 0.7409 - loss: 0.5359\n",
      "Epoch 54/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 779us/step - accuracy: 0.7359 - loss: 0.5414\n",
      "Epoch 55/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 869us/step - accuracy: 0.7369 - loss: 0.5364\n",
      "Epoch 56/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 776us/step - accuracy: 0.7353 - loss: 0.5377\n",
      "Epoch 57/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 768us/step - accuracy: 0.7374 - loss: 0.5377\n",
      "Epoch 58/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 868us/step - accuracy: 0.7401 - loss: 0.5333\n",
      "Epoch 59/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 772us/step - accuracy: 0.7323 - loss: 0.5419\n",
      "Epoch 60/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 766us/step - accuracy: 0.7393 - loss: 0.5358\n",
      "Epoch 61/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 868us/step - accuracy: 0.7399 - loss: 0.5363\n",
      "Epoch 62/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 768us/step - accuracy: 0.7364 - loss: 0.5366\n",
      "Epoch 63/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 766us/step - accuracy: 0.7425 - loss: 0.5315\n",
      "Epoch 64/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 827us/step - accuracy: 0.7348 - loss: 0.5400\n",
      "Epoch 65/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 754us/step - accuracy: 0.7348 - loss: 0.5407\n",
      "Epoch 66/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 783us/step - accuracy: 0.7400 - loss: 0.5345\n",
      "Epoch 67/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 809us/step - accuracy: 0.7421 - loss: 0.5337\n",
      "Epoch 68/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 802us/step - accuracy: 0.7350 - loss: 0.5394\n",
      "Epoch 69/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 817us/step - accuracy: 0.7388 - loss: 0.5360\n",
      "Epoch 70/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 915us/step - accuracy: 0.7375 - loss: 0.5378\n",
      "Epoch 71/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 765us/step - accuracy: 0.7457 - loss: 0.5297\n",
      "Epoch 72/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 763us/step - accuracy: 0.7397 - loss: 0.5324\n",
      "Epoch 73/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 852us/step - accuracy: 0.7390 - loss: 0.5352\n",
      "Epoch 74/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 755us/step - accuracy: 0.7404 - loss: 0.5351\n",
      "Epoch 75/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 766us/step - accuracy: 0.7377 - loss: 0.5405\n",
      "Epoch 76/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 880us/step - accuracy: 0.7365 - loss: 0.5374\n",
      "Epoch 77/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 796us/step - accuracy: 0.7363 - loss: 0.5380\n",
      "Epoch 78/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 752us/step - accuracy: 0.7435 - loss: 0.5302\n",
      "Epoch 79/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 849us/step - accuracy: 0.7410 - loss: 0.5348\n",
      "Epoch 80/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 778us/step - accuracy: 0.7368 - loss: 0.5372\n",
      "Epoch 81/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 760us/step - accuracy: 0.7435 - loss: 0.5328\n",
      "Epoch 82/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 828us/step - accuracy: 0.7424 - loss: 0.5298\n",
      "Epoch 83/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 772us/step - accuracy: 0.7387 - loss: 0.5350\n",
      "Epoch 84/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 765us/step - accuracy: 0.7398 - loss: 0.5359\n",
      "Epoch 85/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 918us/step - accuracy: 0.7401 - loss: 0.5345\n",
      "Epoch 86/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 768us/step - accuracy: 0.7393 - loss: 0.5349\n",
      "Epoch 87/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 870us/step - accuracy: 0.7398 - loss: 0.5354\n",
      "Epoch 88/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 777us/step - accuracy: 0.7440 - loss: 0.5300\n",
      "Epoch 89/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 803us/step - accuracy: 0.7372 - loss: 0.5365\n",
      "Epoch 90/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 888us/step - accuracy: 0.7399 - loss: 0.5343\n",
      "Epoch 91/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 772us/step - accuracy: 0.7381 - loss: 0.5364\n",
      "Epoch 92/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 761us/step - accuracy: 0.7377 - loss: 0.5348\n",
      "Epoch 93/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 871us/step - accuracy: 0.7427 - loss: 0.5339\n",
      "Epoch 94/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 767us/step - accuracy: 0.7362 - loss: 0.5349\n",
      "Epoch 95/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 760us/step - accuracy: 0.7379 - loss: 0.5370\n",
      "Epoch 96/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 856us/step - accuracy: 0.7445 - loss: 0.5287\n",
      "Epoch 97/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 781us/step - accuracy: 0.7420 - loss: 0.5324\n",
      "Epoch 98/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 761us/step - accuracy: 0.7424 - loss: 0.5306\n",
      "Epoch 99/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 0.7436 - loss: 0.5307\n",
      "Epoch 100/100\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 776us/step - accuracy: 0.7394 - loss: 0.5330\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - 647us/step - accuracy: 0.7290 - loss: 0.5582\n",
      "Loss: 0.5582443475723267, Accuracy: 0.7289795875549316\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=h5\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Export our model to HDF5 file\n",
    "nn.save(\"AlphabetSoupCharity.h5\", save_format='h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Increase Number of Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rmt20\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_134\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_134\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_578 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,720</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_579 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,430</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_580 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">310</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_581 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_578 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │         \u001b[38;5;34m6,720\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_579 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │         \u001b[38;5;34m2,430\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_580 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m310\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_581 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m11\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,471</span> (37.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,471\u001b[0m (37.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,471</span> (37.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,471\u001b[0m (37.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "input_features = len(X_train[0])\n",
    "layer1 =  80\n",
    "layer2 = 30\n",
    "layer3 = 10\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=layer1, activation=\"relu\", input_dim=input_features))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=layer2, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=layer3, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1076,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 885us/step - accuracy: 0.7030 - loss: 0.5890\n",
      "Epoch 2/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7325 - loss: 0.5494\n",
      "Epoch 3/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 777us/step - accuracy: 0.7260 - loss: 0.5510\n",
      "Epoch 4/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 767us/step - accuracy: 0.7333 - loss: 0.5449\n",
      "Epoch 5/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 918us/step - accuracy: 0.7394 - loss: 0.5404\n",
      "Epoch 6/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 780us/step - accuracy: 0.7320 - loss: 0.5433\n",
      "Epoch 7/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 769us/step - accuracy: 0.7353 - loss: 0.5443\n",
      "Epoch 8/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 888us/step - accuracy: 0.7341 - loss: 0.5438\n",
      "Epoch 9/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 764us/step - accuracy: 0.7414 - loss: 0.5346\n",
      "Epoch 10/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 775us/step - accuracy: 0.7408 - loss: 0.5365\n",
      "Epoch 11/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 901us/step - accuracy: 0.7413 - loss: 0.5374\n",
      "Epoch 12/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 766us/step - accuracy: 0.7362 - loss: 0.5383\n",
      "Epoch 13/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 771us/step - accuracy: 0.7362 - loss: 0.5399\n",
      "Epoch 14/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 909us/step - accuracy: 0.7359 - loss: 0.5390\n",
      "Epoch 15/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 754us/step - accuracy: 0.7367 - loss: 0.5404\n",
      "Epoch 16/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 736us/step - accuracy: 0.7381 - loss: 0.5371\n",
      "Epoch 17/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 854us/step - accuracy: 0.7333 - loss: 0.5404\n",
      "Epoch 18/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 740us/step - accuracy: 0.7356 - loss: 0.5400\n",
      "Epoch 19/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 729us/step - accuracy: 0.7378 - loss: 0.5406\n",
      "Epoch 20/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851us/step - accuracy: 0.7408 - loss: 0.5317\n",
      "Epoch 21/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 749us/step - accuracy: 0.7338 - loss: 0.5400\n",
      "Epoch 22/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 738us/step - accuracy: 0.7382 - loss: 0.5375\n",
      "Epoch 23/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 0.7365 - loss: 0.5370\n",
      "Epoch 24/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 757us/step - accuracy: 0.7362 - loss: 0.5386\n",
      "Epoch 25/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 730us/step - accuracy: 0.7371 - loss: 0.5370\n",
      "Epoch 26/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 848us/step - accuracy: 0.7352 - loss: 0.5397\n",
      "Epoch 27/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 734us/step - accuracy: 0.7359 - loss: 0.5384\n",
      "Epoch 28/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 747us/step - accuracy: 0.7429 - loss: 0.5291\n",
      "Epoch 29/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 865us/step - accuracy: 0.7406 - loss: 0.5349\n",
      "Epoch 30/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 767us/step - accuracy: 0.7362 - loss: 0.5387\n",
      "Epoch 31/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 747us/step - accuracy: 0.7367 - loss: 0.5393\n",
      "Epoch 32/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 879us/step - accuracy: 0.7387 - loss: 0.5365\n",
      "Epoch 33/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 743us/step - accuracy: 0.7378 - loss: 0.5347\n",
      "Epoch 34/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 745us/step - accuracy: 0.7311 - loss: 0.5422\n",
      "Epoch 35/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 0.7397 - loss: 0.5337\n",
      "Epoch 36/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 732us/step - accuracy: 0.7444 - loss: 0.5286\n",
      "Epoch 37/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 827us/step - accuracy: 0.7369 - loss: 0.5361\n",
      "Epoch 38/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 777us/step - accuracy: 0.7354 - loss: 0.5364\n",
      "Epoch 39/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 734us/step - accuracy: 0.7420 - loss: 0.5336\n",
      "Epoch 40/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838us/step - accuracy: 0.7371 - loss: 0.5362\n",
      "Epoch 41/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 757us/step - accuracy: 0.7385 - loss: 0.5330\n",
      "Epoch 42/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 764us/step - accuracy: 0.7383 - loss: 0.5356\n",
      "Epoch 43/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841us/step - accuracy: 0.7388 - loss: 0.5343\n",
      "Epoch 44/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 770us/step - accuracy: 0.7386 - loss: 0.5340\n",
      "Epoch 45/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 727us/step - accuracy: 0.7379 - loss: 0.5316\n",
      "Epoch 46/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 863us/step - accuracy: 0.7397 - loss: 0.5352\n",
      "Epoch 47/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 734us/step - accuracy: 0.7417 - loss: 0.5314\n",
      "Epoch 48/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 731us/step - accuracy: 0.7416 - loss: 0.5307\n",
      "Epoch 49/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 867us/step - accuracy: 0.7372 - loss: 0.5365\n",
      "Epoch 50/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 741us/step - accuracy: 0.7385 - loss: 0.5307\n",
      "Epoch 51/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 733us/step - accuracy: 0.7395 - loss: 0.5362\n",
      "Epoch 52/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 855us/step - accuracy: 0.7419 - loss: 0.5292\n",
      "Epoch 53/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 737us/step - accuracy: 0.7358 - loss: 0.5347\n",
      "Epoch 54/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 743us/step - accuracy: 0.7417 - loss: 0.5325\n",
      "Epoch 55/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 801us/step - accuracy: 0.7407 - loss: 0.5308\n",
      "Epoch 56/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 729us/step - accuracy: 0.7402 - loss: 0.5310\n",
      "Epoch 57/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 740us/step - accuracy: 0.7402 - loss: 0.5337\n",
      "Epoch 58/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 854us/step - accuracy: 0.7426 - loss: 0.5300\n",
      "Epoch 59/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 733us/step - accuracy: 0.7402 - loss: 0.5305\n",
      "Epoch 60/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 740us/step - accuracy: 0.7388 - loss: 0.5328\n",
      "Epoch 61/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 799us/step - accuracy: 0.7403 - loss: 0.5284\n",
      "Epoch 62/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 742us/step - accuracy: 0.7391 - loss: 0.5315\n",
      "Epoch 63/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 738us/step - accuracy: 0.7428 - loss: 0.5314\n",
      "Epoch 64/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 869us/step - accuracy: 0.7418 - loss: 0.5293\n",
      "Epoch 65/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 735us/step - accuracy: 0.7402 - loss: 0.5305\n",
      "Epoch 66/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 739us/step - accuracy: 0.7389 - loss: 0.5326\n",
      "Epoch 67/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838us/step - accuracy: 0.7389 - loss: 0.5339\n",
      "Epoch 68/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 752us/step - accuracy: 0.7404 - loss: 0.5337\n",
      "Epoch 69/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 758us/step - accuracy: 0.7427 - loss: 0.5307\n",
      "Epoch 70/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 776us/step - accuracy: 0.7433 - loss: 0.5275\n",
      "Epoch 71/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 744us/step - accuracy: 0.7368 - loss: 0.5356\n",
      "Epoch 72/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 797us/step - accuracy: 0.7391 - loss: 0.5331\n",
      "Epoch 73/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 752us/step - accuracy: 0.7420 - loss: 0.5307\n",
      "Epoch 74/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 735us/step - accuracy: 0.7429 - loss: 0.5271\n",
      "Epoch 75/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 0.7451 - loss: 0.5253\n",
      "Epoch 76/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 740us/step - accuracy: 0.7454 - loss: 0.5251\n",
      "Epoch 77/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 733us/step - accuracy: 0.7439 - loss: 0.5294\n",
      "Epoch 78/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 865us/step - accuracy: 0.7436 - loss: 0.5277\n",
      "Epoch 79/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 755us/step - accuracy: 0.7467 - loss: 0.5266\n",
      "Epoch 80/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 743us/step - accuracy: 0.7432 - loss: 0.5283\n",
      "Epoch 81/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 866us/step - accuracy: 0.7432 - loss: 0.5306\n",
      "Epoch 82/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 758us/step - accuracy: 0.7396 - loss: 0.5316\n",
      "Epoch 83/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 817us/step - accuracy: 0.7407 - loss: 0.5315\n",
      "Epoch 84/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 759us/step - accuracy: 0.7405 - loss: 0.5320\n",
      "Epoch 85/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 742us/step - accuracy: 0.7433 - loss: 0.5289\n",
      "Epoch 86/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 873us/step - accuracy: 0.7405 - loss: 0.5287\n",
      "Epoch 87/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 750us/step - accuracy: 0.7418 - loss: 0.5285\n",
      "Epoch 88/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 741us/step - accuracy: 0.7400 - loss: 0.5280\n",
      "Epoch 89/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 857us/step - accuracy: 0.7450 - loss: 0.5229\n",
      "Epoch 90/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 753us/step - accuracy: 0.7381 - loss: 0.5343\n",
      "Epoch 91/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 740us/step - accuracy: 0.7446 - loss: 0.5262\n",
      "Epoch 92/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 861us/step - accuracy: 0.7431 - loss: 0.5267\n",
      "Epoch 93/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 749us/step - accuracy: 0.7456 - loss: 0.5261\n",
      "Epoch 94/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851us/step - accuracy: 0.7439 - loss: 0.5273\n",
      "Epoch 95/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 750us/step - accuracy: 0.7447 - loss: 0.5286\n",
      "Epoch 96/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 747us/step - accuracy: 0.7447 - loss: 0.5244\n",
      "Epoch 97/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 863us/step - accuracy: 0.7462 - loss: 0.5205\n",
      "Epoch 98/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 748us/step - accuracy: 0.7427 - loss: 0.5289\n",
      "Epoch 99/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 748us/step - accuracy: 0.7390 - loss: 0.5313\n",
      "Epoch 100/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 828us/step - accuracy: 0.7410 - loss: 0.5286\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - 2ms/step - accuracy: 0.7287 - loss: 0.5594\n",
      "Loss: 0.5594280362129211, Accuracy: 0.7287463545799255\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increase Layers(n=80,30,10,1): 0.7287463545799255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Increase Number of Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rmt20\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_139\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_139\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_594 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_595 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,840</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_596 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_594 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)            │        \u001b[38;5;34m10,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_595 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │         \u001b[38;5;34m4,840\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_596 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m41\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,961</span> (58.44 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,961\u001b[0m (58.44 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,961</span> (58.44 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m14,961\u001b[0m (58.44 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "input_features = len(X_train[0])\n",
    "layer1 =  120\n",
    "layer2 = 40\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=layer1, activation=\"relu\", input_dim=input_features))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 934us/step - accuracy: 0.7185 - loss: 0.5764\n",
      "Epoch 2/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 883us/step - accuracy: 0.7355 - loss: 0.5482\n",
      "Epoch 3/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 743us/step - accuracy: 0.7320 - loss: 0.5492\n",
      "Epoch 4/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 971us/step - accuracy: 0.7296 - loss: 0.5467\n",
      "Epoch 5/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 773us/step - accuracy: 0.7326 - loss: 0.5446\n",
      "Epoch 6/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 771us/step - accuracy: 0.7294 - loss: 0.5472\n",
      "Epoch 7/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 899us/step - accuracy: 0.7318 - loss: 0.5477\n",
      "Epoch 8/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851us/step - accuracy: 0.7346 - loss: 0.5414\n",
      "Epoch 9/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 878us/step - accuracy: 0.7381 - loss: 0.5393\n",
      "Epoch 10/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 764us/step - accuracy: 0.7423 - loss: 0.5337\n",
      "Epoch 11/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 755us/step - accuracy: 0.7349 - loss: 0.5392\n",
      "Epoch 12/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 866us/step - accuracy: 0.7364 - loss: 0.5378\n",
      "Epoch 13/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 809us/step - accuracy: 0.7363 - loss: 0.5440\n",
      "Epoch 14/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 768us/step - accuracy: 0.7346 - loss: 0.5380\n",
      "Epoch 15/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 898us/step - accuracy: 0.7352 - loss: 0.5391\n",
      "Epoch 16/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 736us/step - accuracy: 0.7384 - loss: 0.5369\n",
      "Epoch 17/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 759us/step - accuracy: 0.7411 - loss: 0.5346\n",
      "Epoch 18/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 869us/step - accuracy: 0.7354 - loss: 0.5409\n",
      "Epoch 19/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 743us/step - accuracy: 0.7391 - loss: 0.5374\n",
      "Epoch 20/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 752us/step - accuracy: 0.7382 - loss: 0.5372\n",
      "Epoch 21/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 0.7358 - loss: 0.5388\n",
      "Epoch 22/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 707us/step - accuracy: 0.7341 - loss: 0.5408\n",
      "Epoch 23/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 703us/step - accuracy: 0.7394 - loss: 0.5351\n",
      "Epoch 24/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 973us/step - accuracy: 0.7403 - loss: 0.5350\n",
      "Epoch 25/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 761us/step - accuracy: 0.7443 - loss: 0.5316\n",
      "Epoch 26/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 719us/step - accuracy: 0.7399 - loss: 0.5356\n",
      "Epoch 27/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 941us/step - accuracy: 0.7345 - loss: 0.5384\n",
      "Epoch 28/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - accuracy: 0.7435 - loss: 0.5308\n",
      "Epoch 29/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 744us/step - accuracy: 0.7390 - loss: 0.5366\n",
      "Epoch 30/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 0.7411 - loss: 0.5330\n",
      "Epoch 31/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 0.7395 - loss: 0.5339\n",
      "Epoch 32/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 800us/step - accuracy: 0.7413 - loss: 0.5354\n",
      "Epoch 33/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 764us/step - accuracy: 0.7447 - loss: 0.5308\n",
      "Epoch 34/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 750us/step - accuracy: 0.7408 - loss: 0.5319\n",
      "Epoch 35/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - accuracy: 0.7425 - loss: 0.5313\n",
      "Epoch 36/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 762us/step - accuracy: 0.7407 - loss: 0.5306\n",
      "Epoch 37/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 708us/step - accuracy: 0.7392 - loss: 0.5340\n",
      "Epoch 38/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 733us/step - accuracy: 0.7426 - loss: 0.5294\n",
      "Epoch 39/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - accuracy: 0.7442 - loss: 0.5305\n",
      "Epoch 40/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - accuracy: 0.7403 - loss: 0.5360\n",
      "Epoch 41/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 747us/step - accuracy: 0.7412 - loss: 0.5357\n",
      "Epoch 42/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 845us/step - accuracy: 0.7410 - loss: 0.5326\n",
      "Epoch 43/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - accuracy: 0.7385 - loss: 0.5358\n",
      "Epoch 44/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 722us/step - accuracy: 0.7400 - loss: 0.5314\n",
      "Epoch 45/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 867us/step - accuracy: 0.7445 - loss: 0.5294\n",
      "Epoch 46/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - accuracy: 0.7477 - loss: 0.5286\n",
      "Epoch 47/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 718us/step - accuracy: 0.7434 - loss: 0.5295\n",
      "Epoch 48/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 854us/step - accuracy: 0.7387 - loss: 0.5346\n",
      "Epoch 49/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - accuracy: 0.7398 - loss: 0.5295\n",
      "Epoch 50/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721us/step - accuracy: 0.7376 - loss: 0.5332\n",
      "Epoch 51/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - accuracy: 0.7396 - loss: 0.5320\n",
      "Epoch 52/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 730us/step - accuracy: 0.7447 - loss: 0.5277\n",
      "Epoch 53/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 714us/step - accuracy: 0.7392 - loss: 0.5347\n",
      "Epoch 54/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 839us/step - accuracy: 0.7402 - loss: 0.5316\n",
      "Epoch 55/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - accuracy: 0.7406 - loss: 0.5324\n",
      "Epoch 56/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 725us/step - accuracy: 0.7399 - loss: 0.5331\n",
      "Epoch 57/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 769us/step - accuracy: 0.7416 - loss: 0.5302\n",
      "Epoch 58/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - accuracy: 0.7428 - loss: 0.5296\n",
      "Epoch 59/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - accuracy: 0.7421 - loss: 0.5286\n",
      "Epoch 60/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 855us/step - accuracy: 0.7375 - loss: 0.5366\n",
      "Epoch 61/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 707us/step - accuracy: 0.7391 - loss: 0.5331\n",
      "Epoch 62/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - accuracy: 0.7440 - loss: 0.5294\n",
      "Epoch 63/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 842us/step - accuracy: 0.7440 - loss: 0.5290\n",
      "Epoch 64/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - accuracy: 0.7405 - loss: 0.5303\n",
      "Epoch 65/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 707us/step - accuracy: 0.7407 - loss: 0.5301\n",
      "Epoch 66/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 852us/step - accuracy: 0.7441 - loss: 0.5297\n",
      "Epoch 67/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - accuracy: 0.7356 - loss: 0.5370\n",
      "Epoch 68/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713us/step - accuracy: 0.7400 - loss: 0.5320\n",
      "Epoch 69/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 842us/step - accuracy: 0.7412 - loss: 0.5317\n",
      "Epoch 70/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 714us/step - accuracy: 0.7451 - loss: 0.5240\n",
      "Epoch 71/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726us/step - accuracy: 0.7438 - loss: 0.5281\n",
      "Epoch 72/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847us/step - accuracy: 0.7403 - loss: 0.5325\n",
      "Epoch 73/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 733us/step - accuracy: 0.7381 - loss: 0.5349\n",
      "Epoch 74/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 815us/step - accuracy: 0.7386 - loss: 0.5312\n",
      "Epoch 75/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 736us/step - accuracy: 0.7474 - loss: 0.5247\n",
      "Epoch 76/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - accuracy: 0.7401 - loss: 0.5326\n",
      "Epoch 77/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 830us/step - accuracy: 0.7399 - loss: 0.5320\n",
      "Epoch 78/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 732us/step - accuracy: 0.7455 - loss: 0.5240\n",
      "Epoch 79/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - accuracy: 0.7394 - loss: 0.5317\n",
      "Epoch 80/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 833us/step - accuracy: 0.7405 - loss: 0.5331\n",
      "Epoch 81/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721us/step - accuracy: 0.7435 - loss: 0.5275\n",
      "Epoch 82/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713us/step - accuracy: 0.7400 - loss: 0.5311\n",
      "Epoch 83/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 837us/step - accuracy: 0.7457 - loss: 0.5274\n",
      "Epoch 84/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 724us/step - accuracy: 0.7403 - loss: 0.5274\n",
      "Epoch 85/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 729us/step - accuracy: 0.7408 - loss: 0.5290\n",
      "Epoch 86/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 789us/step - accuracy: 0.7437 - loss: 0.5269\n",
      "Epoch 87/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - accuracy: 0.7471 - loss: 0.5264\n",
      "Epoch 88/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - accuracy: 0.7430 - loss: 0.5296\n",
      "Epoch 89/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847us/step - accuracy: 0.7483 - loss: 0.5219\n",
      "Epoch 90/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713us/step - accuracy: 0.7421 - loss: 0.5285\n",
      "Epoch 91/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 890us/step - accuracy: 0.7432 - loss: 0.5263\n",
      "Epoch 92/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 746us/step - accuracy: 0.7426 - loss: 0.5301\n",
      "Epoch 93/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 724us/step - accuracy: 0.7411 - loss: 0.5332\n",
      "Epoch 94/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841us/step - accuracy: 0.7437 - loss: 0.5270\n",
      "Epoch 95/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 746us/step - accuracy: 0.7420 - loss: 0.5260\n",
      "Epoch 96/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 735us/step - accuracy: 0.7455 - loss: 0.5264\n",
      "Epoch 97/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 864us/step - accuracy: 0.7443 - loss: 0.5254\n",
      "Epoch 98/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 731us/step - accuracy: 0.7438 - loss: 0.5273\n",
      "Epoch 99/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - accuracy: 0.7365 - loss: 0.5323\n",
      "Epoch 100/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 843us/step - accuracy: 0.7455 - loss: 0.5273\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 - 0s - 1ms/step - accuracy: 0.7275 - loss: 0.5691\n",
      "Loss: 0.5690823793411255, Accuracy: 0.7275024056434631\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increase Neurons(n=100,40): 0.7278134226799011\n",
    "### Increase Neurons(n=120,40): 0.7275024056434631\n",
    "### Increase Neurons(n=100,60): 0.7263362407684326"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change Activation Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_142\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_142\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_603 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,720</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_604 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,430</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_605 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_603 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │         \u001b[38;5;34m6,720\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_604 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │         \u001b[38;5;34m2,430\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_605 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m31\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,181</span> (35.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,181\u001b[0m (35.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,181</span> (35.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,181\u001b[0m (35.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "input_features = len(X_train[0])\n",
    "layer1 =  80\n",
    "layer2 = 30\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=layer1, activation=\"relu\", input_dim=input_features))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"relu\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 801us/step - accuracy: 0.6802 - loss: 1.5002\n",
      "Epoch 2/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 907us/step - accuracy: 0.7167 - loss: 1.0852\n",
      "Epoch 3/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 764us/step - accuracy: 0.7113 - loss: 0.9528\n",
      "Epoch 4/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 749us/step - accuracy: 0.6975 - loss: 0.9799\n",
      "Epoch 5/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 741us/step - accuracy: 0.7304 - loss: 0.7589\n",
      "Epoch 6/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 957us/step - accuracy: 0.7293 - loss: 0.7471\n",
      "Epoch 7/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - accuracy: 0.7299 - loss: 0.8465\n",
      "Epoch 8/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 741us/step - accuracy: 0.7196 - loss: 0.7866\n",
      "Epoch 9/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 854us/step - accuracy: 0.7311 - loss: 0.7137\n",
      "Epoch 10/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - accuracy: 0.7255 - loss: 0.7226\n",
      "Epoch 11/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 733us/step - accuracy: 0.7141 - loss: 0.7431\n",
      "Epoch 12/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 834us/step - accuracy: 0.7271 - loss: 0.7283\n",
      "Epoch 13/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 719us/step - accuracy: 0.7269 - loss: 0.7350\n",
      "Epoch 14/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - accuracy: 0.7233 - loss: 0.7098\n",
      "Epoch 15/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 865us/step - accuracy: 0.7370 - loss: 0.7110\n",
      "Epoch 16/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - accuracy: 0.7311 - loss: 0.7210\n",
      "Epoch 17/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - accuracy: 0.7282 - loss: 0.7118\n",
      "Epoch 18/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 844us/step - accuracy: 0.7207 - loss: 0.7142\n",
      "Epoch 19/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 705us/step - accuracy: 0.7259 - loss: 0.6785\n",
      "Epoch 20/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 707us/step - accuracy: 0.7340 - loss: 0.6825\n",
      "Epoch 21/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 832us/step - accuracy: 0.7153 - loss: 0.6686\n",
      "Epoch 22/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - accuracy: 0.7388 - loss: 0.6524\n",
      "Epoch 23/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 725us/step - accuracy: 0.7187 - loss: 0.6615\n",
      "Epoch 24/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 805us/step - accuracy: 0.7224 - loss: 0.6799\n",
      "Epoch 25/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726us/step - accuracy: 0.7252 - loss: 0.6548\n",
      "Epoch 26/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721us/step - accuracy: 0.7315 - loss: 0.6421\n",
      "Epoch 27/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - accuracy: 0.7235 - loss: 0.6488\n",
      "Epoch 28/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 830us/step - accuracy: 0.7265 - loss: 0.6553\n",
      "Epoch 29/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - accuracy: 0.7303 - loss: 0.6453\n",
      "Epoch 30/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 707us/step - accuracy: 0.7339 - loss: 0.6192\n",
      "Epoch 31/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 829us/step - accuracy: 0.6982 - loss: 0.6431\n",
      "Epoch 32/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713us/step - accuracy: 0.7276 - loss: 0.6480\n",
      "Epoch 33/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - accuracy: 0.7317 - loss: 0.6247\n",
      "Epoch 34/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 828us/step - accuracy: 0.7341 - loss: 0.6189\n",
      "Epoch 35/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - accuracy: 0.7322 - loss: 0.6312\n",
      "Epoch 36/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - accuracy: 0.7123 - loss: 0.6195\n",
      "Epoch 37/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 794us/step - accuracy: 0.7279 - loss: 0.6012\n",
      "Epoch 38/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721us/step - accuracy: 0.7326 - loss: 0.5909\n",
      "Epoch 39/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 714us/step - accuracy: 0.7330 - loss: 0.5951\n",
      "Epoch 40/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825us/step - accuracy: 0.7356 - loss: 0.5923\n",
      "Epoch 41/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 718us/step - accuracy: 0.7312 - loss: 0.5934\n",
      "Epoch 42/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - accuracy: 0.7267 - loss: 0.5946\n",
      "Epoch 43/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825us/step - accuracy: 0.7310 - loss: 0.5953\n",
      "Epoch 44/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - accuracy: 0.7361 - loss: 0.5929\n",
      "Epoch 45/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 704us/step - accuracy: 0.7297 - loss: 0.5935\n",
      "Epoch 46/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838us/step - accuracy: 0.7325 - loss: 0.5928\n",
      "Epoch 47/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 719us/step - accuracy: 0.7324 - loss: 0.6038\n",
      "Epoch 48/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - accuracy: 0.7254 - loss: 0.6051\n",
      "Epoch 49/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 830us/step - accuracy: 0.7332 - loss: 0.5990\n",
      "Epoch 50/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - accuracy: 0.7346 - loss: 0.5852\n",
      "Epoch 51/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 723us/step - accuracy: 0.7258 - loss: 0.6018\n",
      "Epoch 52/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 740us/step - accuracy: 0.7365 - loss: 0.5836\n",
      "Epoch 53/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 749us/step - accuracy: 0.7318 - loss: 0.5978\n",
      "Epoch 54/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - accuracy: 0.7350 - loss: 0.5912\n",
      "Epoch 55/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 719us/step - accuracy: 0.7103 - loss: 0.6073\n",
      "Epoch 56/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 830us/step - accuracy: 0.7329 - loss: 0.6211\n",
      "Epoch 57/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 704us/step - accuracy: 0.7339 - loss: 0.6072\n",
      "Epoch 58/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 702us/step - accuracy: 0.7321 - loss: 0.6172\n",
      "Epoch 59/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838us/step - accuracy: 0.7350 - loss: 0.6086\n",
      "Epoch 60/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 705us/step - accuracy: 0.7337 - loss: 0.6161\n",
      "Epoch 61/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - accuracy: 0.7331 - loss: 0.5842\n",
      "Epoch 62/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 854us/step - accuracy: 0.7386 - loss: 0.6002\n",
      "Epoch 63/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - accuracy: 0.7349 - loss: 0.5929\n",
      "Epoch 64/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 707us/step - accuracy: 0.7379 - loss: 0.5936\n",
      "Epoch 65/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 820us/step - accuracy: 0.7322 - loss: 0.5891\n",
      "Epoch 66/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713us/step - accuracy: 0.7304 - loss: 0.5992\n",
      "Epoch 67/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - accuracy: 0.7330 - loss: 0.6058\n",
      "Epoch 68/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 829us/step - accuracy: 0.7338 - loss: 0.5893\n",
      "Epoch 69/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - accuracy: 0.7338 - loss: 0.5903\n",
      "Epoch 70/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 719us/step - accuracy: 0.7392 - loss: 0.5864\n",
      "Epoch 71/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 848us/step - accuracy: 0.7271 - loss: 0.5975\n",
      "Epoch 72/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 719us/step - accuracy: 0.7368 - loss: 0.5777\n",
      "Epoch 73/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 734us/step - accuracy: 0.7339 - loss: 0.5869\n",
      "Epoch 74/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 730us/step - accuracy: 0.7376 - loss: 0.5908\n",
      "Epoch 75/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726us/step - accuracy: 0.7339 - loss: 0.5895\n",
      "Epoch 76/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 826us/step - accuracy: 0.7339 - loss: 0.6046\n",
      "Epoch 77/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 766us/step - accuracy: 0.7372 - loss: 0.5889\n",
      "Epoch 78/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 742us/step - accuracy: 0.7380 - loss: 0.6042\n",
      "Epoch 79/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877us/step - accuracy: 0.7355 - loss: 0.5928\n",
      "Epoch 80/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 754us/step - accuracy: 0.7374 - loss: 0.6064\n",
      "Epoch 81/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 740us/step - accuracy: 0.7316 - loss: 0.6101\n",
      "Epoch 82/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 822us/step - accuracy: 0.7435 - loss: 0.5936\n",
      "Epoch 83/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 740us/step - accuracy: 0.7208 - loss: 0.6051\n",
      "Epoch 84/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 750us/step - accuracy: 0.7406 - loss: 0.5980\n",
      "Epoch 85/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 929us/step - accuracy: 0.7327 - loss: 0.6005\n",
      "Epoch 86/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 753us/step - accuracy: 0.7400 - loss: 0.5855\n",
      "Epoch 87/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 878us/step - accuracy: 0.7396 - loss: 0.5913\n",
      "Epoch 88/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 740us/step - accuracy: 0.7352 - loss: 0.5935\n",
      "Epoch 89/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 738us/step - accuracy: 0.7293 - loss: 0.6050\n",
      "Epoch 90/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 0.7313 - loss: 0.6033\n",
      "Epoch 91/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 759us/step - accuracy: 0.7372 - loss: 0.5951\n",
      "Epoch 92/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 749us/step - accuracy: 0.7300 - loss: 0.6008\n",
      "Epoch 93/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 879us/step - accuracy: 0.7400 - loss: 0.5848\n",
      "Epoch 94/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 736us/step - accuracy: 0.7372 - loss: 0.5969\n",
      "Epoch 95/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841us/step - accuracy: 0.7339 - loss: 0.6054\n",
      "Epoch 96/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 738us/step - accuracy: 0.7404 - loss: 0.5900\n",
      "Epoch 97/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 731us/step - accuracy: 0.7133 - loss: 0.6451\n",
      "Epoch 98/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877us/step - accuracy: 0.7246 - loss: 0.5961\n",
      "Epoch 99/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 724us/step - accuracy: 0.7357 - loss: 0.5781\n",
      "Epoch 100/100\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 708us/step - accuracy: 0.7358 - loss: 0.5957\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 - 0s - 1ms/step - accuracy: 0.7304 - loss: 0.6303\n",
      "Loss: 0.6303449273109436, Accuracy: 0.7304179072380066\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change Activation Functions(f=\"relu\",\"relu\",\"tanh\"): 0.7296404242515564\n",
    "### Change Activation Functions(f=\"relu\",\"relu\",\"relu\"): 0.7304179072380066"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Attempt at Optimization\n",
    "\n",
    "- Kept the top 8 application types and put the rest as others\n",
    "- Put all classification types whose value_count = 1 as others\n",
    "- Added an additional hidden layer\n",
    "- Changed number of neurons to 100, 40, 10, 1\n",
    "- Increased epochs to 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,040</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">410</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m8,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │         \u001b[38;5;34m4,040\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m410\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m11\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,861</span> (50.24 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,861\u001b[0m (50.24 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,861</span> (50.24 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,861\u001b[0m (50.24 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "input_features = len(X_train[0])\n",
    "layer1 = 100\n",
    "layer2 = 40\n",
    "layer3 = 10\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=layer1, activation=\"relu\", input_dim=input_features))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=layer2, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=layer3, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1366,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 823us/step - accuracy: 0.7018 - loss: 0.5960\n",
      "Epoch 2/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 884us/step - accuracy: 0.7350 - loss: 0.5485\n",
      "Epoch 3/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 778us/step - accuracy: 0.7315 - loss: 0.5468\n",
      "Epoch 4/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 770us/step - accuracy: 0.7339 - loss: 0.5459\n",
      "Epoch 5/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 764us/step - accuracy: 0.7357 - loss: 0.5421\n",
      "Epoch 6/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 895us/step - accuracy: 0.7342 - loss: 0.5463\n",
      "Epoch 7/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 763us/step - accuracy: 0.7347 - loss: 0.5470\n",
      "Epoch 8/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 763us/step - accuracy: 0.7361 - loss: 0.5406\n",
      "Epoch 9/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 880us/step - accuracy: 0.7325 - loss: 0.5448\n",
      "Epoch 10/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 759us/step - accuracy: 0.7377 - loss: 0.5426\n",
      "Epoch 11/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 767us/step - accuracy: 0.7351 - loss: 0.5410\n",
      "Epoch 12/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877us/step - accuracy: 0.7316 - loss: 0.5462\n",
      "Epoch 13/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 745us/step - accuracy: 0.7359 - loss: 0.5394\n",
      "Epoch 14/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 761us/step - accuracy: 0.7358 - loss: 0.5409\n",
      "Epoch 15/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 853us/step - accuracy: 0.7385 - loss: 0.5351\n",
      "Epoch 16/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 740us/step - accuracy: 0.7340 - loss: 0.5386\n",
      "Epoch 17/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 737us/step - accuracy: 0.7399 - loss: 0.5377\n",
      "Epoch 18/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 850us/step - accuracy: 0.7375 - loss: 0.5394\n",
      "Epoch 19/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 732us/step - accuracy: 0.7353 - loss: 0.5398\n",
      "Epoch 20/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 744us/step - accuracy: 0.7375 - loss: 0.5397\n",
      "Epoch 21/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 848us/step - accuracy: 0.7412 - loss: 0.5358\n",
      "Epoch 22/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 729us/step - accuracy: 0.7363 - loss: 0.5370\n",
      "Epoch 23/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 737us/step - accuracy: 0.7381 - loss: 0.5367\n",
      "Epoch 24/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 854us/step - accuracy: 0.7377 - loss: 0.5380\n",
      "Epoch 25/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 742us/step - accuracy: 0.7400 - loss: 0.5348\n",
      "Epoch 26/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 737us/step - accuracy: 0.7401 - loss: 0.5386\n",
      "Epoch 27/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 853us/step - accuracy: 0.7435 - loss: 0.5314\n",
      "Epoch 28/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 742us/step - accuracy: 0.7414 - loss: 0.5317\n",
      "Epoch 29/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 735us/step - accuracy: 0.7388 - loss: 0.5384\n",
      "Epoch 30/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 846us/step - accuracy: 0.7371 - loss: 0.5374\n",
      "Epoch 31/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 737us/step - accuracy: 0.7409 - loss: 0.5360\n",
      "Epoch 32/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 740us/step - accuracy: 0.7418 - loss: 0.5353\n",
      "Epoch 33/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 787us/step - accuracy: 0.7434 - loss: 0.5311\n",
      "Epoch 34/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 755us/step - accuracy: 0.7383 - loss: 0.5376\n",
      "Epoch 35/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 738us/step - accuracy: 0.7383 - loss: 0.5382\n",
      "Epoch 36/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 741us/step - accuracy: 0.7421 - loss: 0.5335\n",
      "Epoch 37/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 794us/step - accuracy: 0.7418 - loss: 0.5337\n",
      "Epoch 38/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 737us/step - accuracy: 0.7410 - loss: 0.5329\n",
      "Epoch 39/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 734us/step - accuracy: 0.7421 - loss: 0.5324\n",
      "Epoch 40/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 843us/step - accuracy: 0.7379 - loss: 0.5352\n",
      "Epoch 41/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 730us/step - accuracy: 0.7386 - loss: 0.5379\n",
      "Epoch 42/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 738us/step - accuracy: 0.7437 - loss: 0.5330\n",
      "Epoch 43/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841us/step - accuracy: 0.7444 - loss: 0.5308\n",
      "Epoch 44/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 730us/step - accuracy: 0.7442 - loss: 0.5309\n",
      "Epoch 45/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 753us/step - accuracy: 0.7389 - loss: 0.5314\n",
      "Epoch 46/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7423 - loss: 0.5290\n",
      "Epoch 47/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 762us/step - accuracy: 0.7436 - loss: 0.5317\n",
      "Epoch 48/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 857us/step - accuracy: 0.7383 - loss: 0.5323\n",
      "Epoch 49/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7392 - loss: 0.5320\n",
      "Epoch 50/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 820us/step - accuracy: 0.7409 - loss: 0.5296\n",
      "Epoch 51/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825us/step - accuracy: 0.7372 - loss: 0.5327\n",
      "Epoch 52/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7411 - loss: 0.5310\n",
      "Epoch 53/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 907us/step - accuracy: 0.7417 - loss: 0.5287\n",
      "Epoch 54/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7447 - loss: 0.5284\n",
      "Epoch 55/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 903us/step - accuracy: 0.7411 - loss: 0.5304\n",
      "Epoch 56/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 928us/step - accuracy: 0.7431 - loss: 0.5287\n",
      "Epoch 57/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7414 - loss: 0.5324\n",
      "Epoch 58/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 916us/step - accuracy: 0.7449 - loss: 0.5274\n",
      "Epoch 59/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 995us/step - accuracy: 0.7404 - loss: 0.5341\n",
      "Epoch 60/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 925us/step - accuracy: 0.7424 - loss: 0.5282\n",
      "Epoch 61/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 932us/step - accuracy: 0.7386 - loss: 0.5319\n",
      "Epoch 62/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7432 - loss: 0.5292\n",
      "Epoch 63/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 890us/step - accuracy: 0.7424 - loss: 0.5291\n",
      "Epoch 64/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 920us/step - accuracy: 0.7379 - loss: 0.5365\n",
      "Epoch 65/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7374 - loss: 0.5335\n",
      "Epoch 66/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 956us/step - accuracy: 0.7391 - loss: 0.5332\n",
      "Epoch 67/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 970us/step - accuracy: 0.7378 - loss: 0.5342\n",
      "Epoch 68/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 859us/step - accuracy: 0.7451 - loss: 0.5286\n",
      "Epoch 69/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877us/step - accuracy: 0.7436 - loss: 0.5290\n",
      "Epoch 70/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7426 - loss: 0.5306\n",
      "Epoch 71/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 893us/step - accuracy: 0.7405 - loss: 0.5307\n",
      "Epoch 72/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 921us/step - accuracy: 0.7381 - loss: 0.5313\n",
      "Epoch 73/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7458 - loss: 0.5266\n",
      "Epoch 74/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 914us/step - accuracy: 0.7458 - loss: 0.5236\n",
      "Epoch 75/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 884us/step - accuracy: 0.7399 - loss: 0.5298\n",
      "Epoch 76/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 971us/step - accuracy: 0.7400 - loss: 0.5315\n",
      "Epoch 77/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 921us/step - accuracy: 0.7449 - loss: 0.5251\n",
      "Epoch 78/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 956us/step - accuracy: 0.7387 - loss: 0.5303\n",
      "Epoch 79/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 981us/step - accuracy: 0.7462 - loss: 0.5251\n",
      "Epoch 80/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 885us/step - accuracy: 0.7421 - loss: 0.5268\n",
      "Epoch 81/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 862us/step - accuracy: 0.7373 - loss: 0.5329\n",
      "Epoch 82/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 864us/step - accuracy: 0.7418 - loss: 0.5286\n",
      "Epoch 83/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7444 - loss: 0.5280\n",
      "Epoch 84/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 985us/step - accuracy: 0.7416 - loss: 0.5281\n",
      "Epoch 85/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7425 - loss: 0.5262\n",
      "Epoch 86/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7428 - loss: 0.5277\n",
      "Epoch 87/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 907us/step - accuracy: 0.7412 - loss: 0.5303\n",
      "Epoch 88/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 990us/step - accuracy: 0.7414 - loss: 0.5290\n",
      "Epoch 89/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 931us/step - accuracy: 0.7429 - loss: 0.5292\n",
      "Epoch 90/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7409 - loss: 0.5300\n",
      "Epoch 91/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 837us/step - accuracy: 0.7432 - loss: 0.5267\n",
      "Epoch 92/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7460 - loss: 0.5249\n",
      "Epoch 93/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 991us/step - accuracy: 0.7371 - loss: 0.5353\n",
      "Epoch 94/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 958us/step - accuracy: 0.7461 - loss: 0.5252\n",
      "Epoch 95/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7407 - loss: 0.5282\n",
      "Epoch 96/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838us/step - accuracy: 0.7410 - loss: 0.5268\n",
      "Epoch 97/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7422 - loss: 0.5299\n",
      "Epoch 98/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 842us/step - accuracy: 0.7416 - loss: 0.5275\n",
      "Epoch 99/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 865us/step - accuracy: 0.7408 - loss: 0.5295\n",
      "Epoch 100/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7442 - loss: 0.5239\n",
      "Epoch 101/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 915us/step - accuracy: 0.7432 - loss: 0.5300\n",
      "Epoch 102/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7440 - loss: 0.5259\n",
      "Epoch 103/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 987us/step - accuracy: 0.7426 - loss: 0.5282\n",
      "Epoch 104/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7429 - loss: 0.5267\n",
      "Epoch 105/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 911us/step - accuracy: 0.7478 - loss: 0.5238\n",
      "Epoch 106/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 866us/step - accuracy: 0.7391 - loss: 0.5292\n",
      "Epoch 107/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7374 - loss: 0.5307\n",
      "Epoch 108/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - accuracy: 0.7463 - loss: 0.5240\n",
      "Epoch 109/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7432 - loss: 0.5269\n",
      "Epoch 110/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 867us/step - accuracy: 0.7409 - loss: 0.5289\n",
      "Epoch 111/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7441 - loss: 0.5269\n",
      "Epoch 112/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 982us/step - accuracy: 0.7375 - loss: 0.5324\n",
      "Epoch 113/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 955us/step - accuracy: 0.7431 - loss: 0.5264\n",
      "Epoch 114/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7413 - loss: 0.5310\n",
      "Epoch 115/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 805us/step - accuracy: 0.7404 - loss: 0.5294\n",
      "Epoch 116/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7388 - loss: 0.5306\n",
      "Epoch 117/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 789us/step - accuracy: 0.7459 - loss: 0.5245\n",
      "Epoch 118/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 917us/step - accuracy: 0.7402 - loss: 0.5306\n",
      "Epoch 119/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 783us/step - accuracy: 0.7413 - loss: 0.5290\n",
      "Epoch 120/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 809us/step - accuracy: 0.7433 - loss: 0.5263\n",
      "Epoch 121/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847us/step - accuracy: 0.7440 - loss: 0.5277\n",
      "Epoch 122/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 812us/step - accuracy: 0.7461 - loss: 0.5224\n",
      "Epoch 123/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 871us/step - accuracy: 0.7451 - loss: 0.5250\n",
      "Epoch 124/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 793us/step - accuracy: 0.7390 - loss: 0.5308\n",
      "Epoch 125/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 735us/step - accuracy: 0.7456 - loss: 0.5244\n",
      "Epoch 126/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 815us/step - accuracy: 0.7431 - loss: 0.5256\n",
      "Epoch 127/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 0.7436 - loss: 0.5274\n",
      "Epoch 128/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 777us/step - accuracy: 0.7445 - loss: 0.5250\n",
      "Epoch 129/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 878us/step - accuracy: 0.7453 - loss: 0.5251\n",
      "Epoch 130/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 845us/step - accuracy: 0.7409 - loss: 0.5297\n",
      "Epoch 131/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 755us/step - accuracy: 0.7438 - loss: 0.5276\n",
      "Epoch 132/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 762us/step - accuracy: 0.7440 - loss: 0.5254\n",
      "Epoch 133/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 736us/step - accuracy: 0.7434 - loss: 0.5271\n",
      "Epoch 134/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 767us/step - accuracy: 0.7438 - loss: 0.5243\n",
      "Epoch 135/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 766us/step - accuracy: 0.7452 - loss: 0.5243\n",
      "Epoch 136/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 737us/step - accuracy: 0.7389 - loss: 0.5300\n",
      "Epoch 137/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847us/step - accuracy: 0.7439 - loss: 0.5229\n",
      "Epoch 138/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 770us/step - accuracy: 0.7440 - loss: 0.5260\n",
      "Epoch 139/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 744us/step - accuracy: 0.7385 - loss: 0.5315\n",
      "Epoch 140/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 846us/step - accuracy: 0.7418 - loss: 0.5250\n",
      "Epoch 141/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 738us/step - accuracy: 0.7442 - loss: 0.5268\n",
      "Epoch 142/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 743us/step - accuracy: 0.7401 - loss: 0.5283\n",
      "Epoch 143/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 809us/step - accuracy: 0.7417 - loss: 0.5286\n",
      "Epoch 144/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 758us/step - accuracy: 0.7445 - loss: 0.5230\n",
      "Epoch 145/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 742us/step - accuracy: 0.7405 - loss: 0.5288\n",
      "Epoch 146/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851us/step - accuracy: 0.7461 - loss: 0.5235\n",
      "Epoch 147/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 743us/step - accuracy: 0.7434 - loss: 0.5241\n",
      "Epoch 148/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 843us/step - accuracy: 0.7437 - loss: 0.5269\n",
      "Epoch 149/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 737us/step - accuracy: 0.7449 - loss: 0.5270\n",
      "Epoch 150/150\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 739us/step - accuracy: 0.7447 - loss: 0.5272\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 - 0s - 1ms/step - accuracy: 0.7306 - loss: 0.5745\n",
      "Loss: 0.5745279788970947, Accuracy: 0.7306122183799744\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=h5\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Export our model to HDF5 file\n",
    "nn.save(\"AlphabetSoupCharity_Optimization.h5\", save_format='h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at Training History Here\n",
    "### Run desired model beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 1370,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a DataFrame containing training history\n",
    "history_df = pd.DataFrame(fit_model.history)\n",
    "\n",
    "# Increase the index by 1 to match the number of epochs\n",
    "history_df.index += 1\n",
    "\n",
    "# Plot the graphs\n",
    "history_df.plot(y=\"loss\")\n",
    "history_df.plot(y=\"accuracy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
